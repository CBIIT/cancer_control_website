<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <!-- meta tags--><meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <!--external style sheets--><link href="../style.css" type="text/css" rel="stylesheet" />
<title>DCCPS</title>
</head>
<body>
<div id="wrapper">
<!-- NCI Banner -->
  <div id="head-row1"><img src="../images/dccps-banner2.gif" alt="National Cancer Institute" width="1000" height="40" usemap="#Map" /></div>
<!-- end of NCI Banner -->

<!-- DCCPS Banner / Search Field -->
<div id="head-row2">
  <div id="left2"><a href="../index.html"><img src="../images/dccps-banner.gif" alt="Cancer Control &amp; Population Sciences Home - NCI's Bridge to Public Health Research, Practice and Policy" width="730" height="68" /></a></div>
  
  <div id="right2">
	<div id="north">
	<a href="http://twitter.com/NCICancerCtrl" title="Twitter">Twitter<img src="../images/twitter-icon.png" title="Twitter" alt="Twitter" width="20" height="20" /></a><a href="../exit_disclaimer.html"><img src="../images/Icon_External_Link.png" width="12" height="12" alt="exit disclaimer" /></a><a href="../cr-communication-videos.html" title="Multimedia">Multimedia<img src="../images/media-icon.gif" title="Multimedia" alt="Multimedia" width="20" height="20" /></a></div>
    <form method="get" action="http://search2.google.cit.nih.gov/search" name="search">
	  <input type="hidden" name="site" value="DCCPS" />
	  <input type="hidden" name="client" value="DCCPS_frontend" />
	  <input type="hidden" name="proxystylesheet" value="DCCPS_frontend" />
  	  <input type="hidden" name="output" value="xml_no_dtd" />
	  <input type="hidden" name="filter" value="0" />
	  <input type="hidden" name="getfields" value="*" />
	  <label for="searchbox"><input id="searchbox" type="text" name="q" size="15" maxlength="255" class="htextf" value="Search" /></label>
	  <input type="image" src="../images/hbutton.gif"  class="hbutton" name="btnG" id="btnG" alt="Search" />
	</form><br class="clearfloat" />
    </div><br class="clearfloat" />
  </div>
<!-- End of DCCPS Banner / Search Field -->
	
<!-- Main Content -->
  <div id="mainarea">
  <!-- Left Column // DCCPS Link / Need Help Banner -->
  <div id="column-left1">
    <div id="dccps-link"><a href="../index.html">Cancer Control &amp; Population Sciences Home</a></div>
    <div class="rounded-border">
      <ul class="slist2">
        <li><a href="../funding.html" style="font-weight:bold;">Funding Opportunities </a></li>
      </ul>
    </div>
    <a href="http://www.cancer.gov/help"><img src="../images/help-tile.jpg" alt="Need Help? Contact us by phone (1-800-422-6237), Web, or e-mail" /></a> </div>
  <!-- End of Left Column // DCCPS Link / Need Help Banner -->
    
  <!-- Right Column // Page Content -->
    <div id="column-mid2">
      <div class="content">
        <h2>Step-By-Step Grant Help</h2>
        <h3>The Grant Writing Process - Design</h3>
        <h3>Design Process Glossary</h3>
        <dl>
          <dt><strong><a name="Accretion" id="Accretion"></a>Accretion</strong></dt>
        </dl>
        —the accumulation of some factor.  Particularly relevant to observational or inobtrusive studies.
        <dl>
          <dt><strong><a name="ANOVA" id="ANOVA"></a>ANOVA</strong></dt>
        </dl>
        —analysis of   variance is a statistical procedure for testing for significant   differences between several group means by determining whether the   relative variation between groups is significantly larger than the   variation within groups.
        <dl>
          <dt><strong><a name="Active/Passive Consent" id="Active/Passive Consent"></a>Active/Passive Consent</strong></dt>
        </dl>
        —active   consent occurs when participants in a study (the subjects) must do   something active to express their consent such as signing a consent   form; while passive consent may be assumed to occur when they answer   questions or participate through their actions without an explicit   action of consent.
        <dl>
          <dt><strong><a name="Adjustments-For-Multiple-Comparisons" id="Adjustments-For-Multiple-Comparisons"></a>Adjustments For Multiple Comparisons</strong></dt>
        </dl>
        —when   several different tests of statistical significance are performed in a   single study, significant results may be found sometimes just by chance.   The more comparisons, the more likely this is to occur.  Several   commonly used procedures such as Sheffe's test and Duncan's multiple   range test adjust for this effect.
        <dl>
          <dt><strong><a name="Alpha" id="Alpha"></a>Alpha</strong></dt>
        </dl>
        —the p-value   at which a finding will be accepted as being statistically significant,   e.g., the probability that the observed relationship is not likely to be   a result of chance or of random fluctuations in the data.
        <p>Typically alpha is set at .05 so a p &lt;.05 would be considered statistically significant.</p>
        <p>—an index of internal consistency in a multi-item measure (Cronbach's   alpha).  The range is .00 to 1.0 with higher values indicating more   homogeneity of the items.</p>
        <dl>
          <dt><strong><a name="Alternate Form" id="Alternate Form"></a>Alternate Form</strong></dt>
        </dl>
        —to   demonstrate this type of reliability, investigators construct two   instruments that measure the same construct, with the expectation that   the scores of the two instruments will be correlated highly with one   another.  Sometimes when investigators construct these instruments,   items on the two forms are only worded slightly differently or arranged   in a different order.
        <dl>
          <dt><strong><a name="Alternative-Hypothesis" id="Alternative-Hypothesis"></a>Alternative Hypothesis</strong></dt>
        </dl>
        —in   tests of significance, the alternate hypothesis is the complement to   the null hypothesis.  The null hypothesis must be something which can be   tested statistically, such as the hypothesis that two means are   identical.  The alternate hypothesis can never be definitively proven,   but is tentatively accepted when (and if) its complement (the null   hypothesis) is rejected.
        <dl>
          <dt><strong><a name="Analyze" id="Analyze"></a>Analyze</strong></dt>
        </dl>
        —open   ended items present a number of problems. The subject may misunderstand   the intent of the item, may lack composition skills, and/or may not   provide salient information. In addition, it is difficult to summarize   the content of lengthy responses. A researcher's misinterpretation of   material provided by the subject can seriously affect the reliability of   results.
        <dl>
          <dt><strong><a name="Anonymity" id="Anonymity"></a>Anonymity</strong></dt>
        </dl>
        —a   common, and effective, way to reduce risks to human subjects in studies   is to preserve their anonymity—that is, to gather data in a way which   makes it impossible to connect specific responses with any particular   respondent.
        <dl>
          <dt><strong><a name="Archival-Data" id="Archival-Data"></a>Archival Data</strong></dt>
        </dl>
        —information   obtained from documents that were developed for some reason other than   as a source of empirical data.  For example, records such as marriage   licenses, arrest records, death certificates, and court records may be   used to assess trends in a certain population. Information such as   market variability may also be obtained from publications such as the   popular press (e.g., newspapers) or trade journals.  If data are being   collected from a study of community trends rather than individuals,   information can be obtained from census tract records which will contain   a variety of demographic data such as the breakdown of ethnicity,   income, and age of the population.  Information about an individual may   also be obtained, usually with that person's permission, from   administrative files such as annual progress reports, medical insurance   claims, etc.
        <p>—Another example is where an investigator wishes to determine if the   drop-out rate for urban high school students is related to drug   involvement.  Examination of police or school records could be used to   identify individuals with drug histories; thus the rate of these   individuals dropping out of school can be compared to that of students   in other categories.</p>
        <dl>
          <dt><strong><a name="Factors That Can Influence The Results Away From Significance" id="Factors That Can Influence The Results Away From Significance"></a>Factors That Can Influence The Results Away From Significance</strong></dt>
        </dl>
        <ol>
          <li>the investigator used poor quality instruments</li>
          <li>the sample may not have been representative of the population of interest</li>
          <li>the sample size may not have been sufficiently large</li>
          <li>the study design was biased against finding a significant result</li>
          <li>third variable effects may have influenced the results</li>
          <li>the relationship of interest may exist in some populations but not others</li>
          <li>error may have influenced the results.  Error can occur during:
            <ul>
              <li>data collection</li>
              <li>data entry</li>
              <li>measurement </li>
              <li>in the response</li>
            </ul>
            <ul>
              <li>from environmental factors</li>
              <li>from social desirability</li>
              <li>from random error</li>
              <li>from poor quality equipment or measures</li>
              <li>from poor calibration of equipment </li>
              <li>in computer programming</li>
            </ul>
          </li>
        </ol>
        <dl>
          <dt><strong><a name="Association" id="Association"></a>Association</strong></dt>
        </dl>
        —a   measure of the relationship between two variables.  Two variables are   associated to the extent that they covary—that is, changes in the value   of one variable are associated with changes in the value of the other.
        <dl>
          <dt><strong><a name="Attrition" id="Attrition"></a>Attrition</strong></dt>
        </dl>
        —the   rate at which subjects drop out of a longitudinal study and consequently   no longer provide information to the researcher.  Reasons for attrition   may vary, but some include:  subjects have moved, become discontent   with their involvement in the study, or have died.  Attrition is rarely   random, and the subjects who remain in the study may not be resemble the   original study sample, thus potentially providing biased results.
        <dl>
          <dt><strong><a name="Beta" id="Beta"></a>Beta</strong></dt>
        </dl>
        —the probability   of making a type II error in statistical hypothesis testing—that is,   the probability of incorrectly failing to reject the null hypothesis   such as concluding there is no significant difference between two means   when there actually is a significant difference.
        <p>—the standardized regression coefficient or path coefficient in a   regression analysis.  It ranges from -1 to +1 with magnitudes near   either extreme representing a nearly perfect relationship and magnitudes   near zero indicating little or no relationship.</p>
        <dl>
          <dt><strong><a name="Between-Group" id="Between-Group"></a>Between Group</strong></dt>
        </dl>
        —between-group   variance is a measure of the differences between groups. It includes   both systematic differences between groups and error or unexplained   variance (estimated by within-group variance).  Between-group variance   is compared to within-group variance to assess the significance of   between-group differences.  If the between-group variance is not   significantly larger than within-group variance, then there is unlikely   to be any systematic difference.
        <dl>
          <dt><strong><a name="Bias" id="Bias"></a>Bias</strong></dt>
        </dl>
        —a condition   that consistently influences the data either toward or away from   statistical significance.  Bias most often runs throughout the dataset,   and has an undue influence the results. Demonstrating that efforts to   reduce the chance of bias is usually a good strategy when preparing a   grant application.
        <p>For example, a study is conducted by a proponent for a certain type   of drug intervention therapy.  The researcher uses a widely accepted   scale of drug abuse which is administered by an interviewer and is used   in this study to assess the client's pre- and post-treatment condition.   Particularly if </p>
        <ul>
          <li>the treatment is found effective,</li>
          <li>the researcher conducts the interviews, and</li>
          <li>no control group is used</li>
        </ul>
        <p>critics will almost surely raise the question of bias.  The   investigator, who is very closely attached to the hypothesis, may well   give the client the&quot;benefit of the doubt&quot; on various items when the   post-treatment interview is given, inflating the observed effect of the   treatment.  Similar criticisms may also arise if the researcher employs   interviewers, if these individuals are trained by the investigator.  The   researcher may be able to transfer biases to those who will conduct the   interview.  Despite using a control group, if the interviewers are not   blind to the subject's treatment status, a charge of bias, which will   not be easily answered, may be leveled at the study. </p>
        <dl>
          <dt><strong><a name="Biased" id="Biased"></a>Biased</strong></dt>
        </dl>
        —a study is   biased if one or more sources of potential bias have not been   effectively controlled.  A good design requires that the researcher take   credible actions to reduce or eliminate likely sources of bias.
        <dl>
          <dt><strong><a name="Blind" id="Blind"></a>Blind</strong></dt>
        </dl>
        —the subject's   treatment condition is not known by either the subject or the   investigator (a single blind study)—or both are unaware of the subject's   status (a double blind study).  A double blind design is almost always   used in clinical trials.
        <dl>
          <dt><strong><a name="Cases" id="Cases"></a>Cases</strong></dt>
        </dl>
        —individuals,   organizations, or other entities who are members of the population to be   studied. Sometimes, especially in medical studies, human subjects may   be called probands.
        <dl>
          <dt><strong><a name="Case-Control" id="Case-Control"></a>Case Control</strong></dt>
        </dl>
        —a   case control study is one in which cases having a condition of interest   (usually a rare condition) are identified, and other individuals which   match them on control variables but do not exhibit the condition of   interest are found to serve as a comparison group.  Case-control studies   provide an inexpensive method to study rare conditions, but have   deficiencies when compared to prospective studies.
        <dl>
          <dt><strong><a name="Case-Variable-Ratio" id="Case-Variable-Ratio"></a>Case/Variable Ratio</strong></dt>
        </dl>
        —the   case/variable ratio is an index for judging some aspects of research   studies.  Generally, statistical analyses are more credible when the   case/variable ratio is high, and less sound when the case/variable ratio   is low.  A guideline for factor analysis, for example, is that there   should be at least 5 cases per variable, or even 10 per variable in its   more stringent version.
        <dl>
          <dt><strong><a name="Categorical" id="Categorical"></a>Categorical</strong></dt>
        </dl>
        —a   variable is said to be categorical when it consists of two or more   nonoverlapping categories.  Categorical variables are noncontinuous.   Examples are gender (male or female), religious orientation, ethnicity,   and so on.
        <dl>
          <dt><strong><a name="Causal" id="Causal"></a>Causal</strong></dt>
        </dl>
        —a   relationship which one or more variables directly influence the outcome   variable. Most studies are designed to provide correlational as opposed   to causal data largely because causal relationships are more costly and   more difficult to prove.  Years ago Koch suggested the following   criteria for demonstrating that a bacteria was responsible for causing a   disease:
        <ol type="a">
          <li>the organism is present in each case</li>
          <li>the organism can be grown in pure culture</li>
          <li>the organism precipitates the disease in inoculated, susceptible animals</li>
          <li>the organism can be recovered from the animal and identified</li>
        </ol>
        <p>However, these criteria do not work well in studies of chronic   noninfectious diseases or of maladaptive behavior.  In such cases,   typically, the following are needed to show that one variable has a   causal relationship with another:</p>
        <ol type="a">
          <li>the variable that is thought to cause the factor of interest should precede the outcome.</li>
          <li>the strength of the association should be significant.</li>
          <li>a dose-response relationships should exist.</li>
          <li>a reversible association should exists. if the causal factor is removed, the risk is reduced.</li>
          <li>the findings should be consistent across studies.</li>
          <li>are the findings plausible—do the results seem reasonable?</li>
        </ol>
        <dl>
          <dt><strong><a name="Chi-Square" id="Chi-Square"></a>Chi Square</strong></dt>
        </dl>
        —a   commonly used statistic for contingency tables providing a test of   significance for nominal variables.  Chi-square does NOT provide a good   measure of association because its upper bound varies directly with the   number of cases.
        <dl>
          <dt><strong><a name="Clinical-Significance" id="Clinical-Significance"></a>Clinical Significance</strong></dt>
        </dl>
        —clinical   significance is to be distinguished from statistical significance.    Studies with extremely large sample sizes can produce results which may   be statistically significant, but represent differences too small to be   of clinical importance.
        <dl>
          <dt><strong><a name="Clinical-Trials" id="Clinical-Trials"></a>Clinical Trials</strong></dt>
        </dl>
        —in   a clinical trial, two or more groups of subjects are given different   treatments—or in the case of a control group, given no treatment at   all—and are followed over a well defined period of time.
        <p>After the data have been collected the groups are compared to one   another on outcome of interest.  These trials consist of subjects who   are assigned—usually by some random procedure—into either a treatment or   a control group.</p>
        <dl>
          <dt><strong><a name="Cluster-Sampling" id="Cluster-Sampling"></a>Cluster Sampling</strong></dt>
        </dl>
        —an   organizational unit is systematically divided into its logical smaller   components; random selection of units are accomplished at each level   beginning at the largest category until the smallest organizational   units are chosen, and the entire group of individuals in the selected   units are assessed.
        <p>—For example, a study is conducted by a large corporation.  First,   departments which for this example represents the largest sampling unit   are randomly selected; next divisions in those departments are randomly   identified and then sections in the divisions are chosen.  All   individuals in the selected sections would then be assessed.  The   potential for bias exists, then, if the various departments (or the   divisions or sections) contain individuals with characteristics   different from the other departments.</p>
        <dl>
          <dt><strong><a name="Coding" id="Coding"></a>Coding</strong></dt>
        </dl>
        —coding is   the process of recording numbers or other symbols to represent   information.  This process typically requires a series of checks to   assure the data produced meet standards of accuracy.
        <dl>
          <dt><strong><a name="Coefficient" id="Coefficient"></a>Coefficient</strong></dt>
        </dl>
        —a   coefficient is a numerical index summarizing a distribution or a   relationship between two or more variables.  Examples include the   correlation coefficient.
        <dl>
          <dt><strong><a name="Cognitive-Level" id="Cognitive-Level"></a>Cognitive Level</strong></dt>
        </dl>
        —the   cognitive level of a population refers to the ability of cases in the   population to understand or perform cognitive tasks which may be   required for data collection in a study.  For example, asking   respondents with little or no education to respond to questions   requiring a college education to understand mismatches the cognitive   demands of the study with the cognitive level of the population studied.
        <dl>
          <dt><strong><a name="Cohort" id="Cohort"></a>Cohort</strong></dt>
        </dl>
        —a cohort is   a group of people of the same generation.  Examples are: 1) students   graduating from high schools in the year 1991; and 2) people born during   the 1920's.
        <dl>
          <dt><strong><a name="Colinearity" id="Colinearity"></a>Colinearity</strong></dt>
        </dl>
        —occurs   when two or more of the independent variables share essentially the   same information.  In other words, these variables are measuring similar   concepts and it is difficult or impossible to separate their effects.
        <p>Coefficients derived in a multivariate equation that suffers from   colinearity can expected to be unstable and should not be cited as   valid.  For example, using two different scales of depression—which are   presumably highly related to one another in the same multivariate   independent variable list.  Including gender and source of subject in   the same manner in a study in which all females came from one source and   all males came from the only other source of subjects.</p>
        <dl>
          <dt><strong><a name="Components-Of-The-Concept" id="Components-Of-The-Concept"></a>Components Of The Concept</strong></dt>
        </dl>
        —complex   concepts may have multiple dimensions or components.  For example, a   concept like alienation might include alienation from work, alienation   from a spouse, or alienation from society in general.
        <dl>
          <dt><strong><a name="Confidence-Intervals" id="Confidence-Intervals"></a>Confidence Intervals</strong></dt>
        </dl>
        —an   interval having a probability of (1 - alpha) of containing the true   parameter value of a statistic.  For example, in a survey estimating the   rate of drug abuse in a population, there may be a 95% confidence that   the true rate is something between 10% and 15%.
        <dl>
          <dt><strong><a name="Confidentiality" id="Confidentiality"></a>Confidentiality</strong></dt>
        </dl>
        —information   is kept confidential when its access is limited to only people   conducting the research for purposes of research and is not provided to   others in a manner permitting them to deduce the identity of   respondents.
        <dl>
          <dt><strong><a name="Confounding-Variables" id="Confounding-Variables"></a>Confounding Variables</strong></dt>
        </dl>
        —variables   related to both the outcome variable and the variables that are thought   to be related to the outcome.  Confounders may affect the results of   the analysis; any relationship between the outcome variable and the   independent variables of interest may exist only because the confounding   variables influence both the outcome and the independent variables.  By   not adjusting for potential confounders, the results of the study may   be of very limited value.
        <dl>
          <dt><strong><a name="Consistent-Instructions" id="Consistent-Instructions"></a>Consistent Instructions</strong></dt>
        </dl>
        —in   experimental studies it is important that researchers administering the   experiment provide a consistent stimulus to each case.  Instructions,   for example, should be said using the same words, with the same tone of   voice, and hopefully understood in the same manner.
        <dl>
          <dt><strong><a name="Construct" id="Construct"></a>Construct</strong></dt>
        </dl>
        —the underlying concept thought to be measured by observable variables.
        <dl>
          <dt><strong><a name="Construct-Validity" id="Construct-Validity"></a>Construct Validity</strong></dt>
        </dl>
        —construct   validity is assessed by examining the empirical relationships between   the scale and measures of other intuitively related concepts.
        <dl>
          <dt><strong><a name="Content" id="Content"></a>Content</strong></dt>
        </dl>
        —a test has content validity if the items are representative of a larger body of knowledge that the sense it might represent.
        <dl>
          <dt><strong><a name="Content-Validity" id="Content-Validity"></a>Content Validity</strong></dt>
        </dl>
        —a test has content validity if the items are representative of a larger body of knowledge that the sense it might represent.
        <dl>
          <dt><strong><a name="Continuous" id="Continuous"></a>Continuous</strong></dt>
        </dl>
        —a continuous variable is one which can have an infinite number of possible values in some specific range.
        <dl>
          <dt><strong><a name="Control" id="Control"></a>Control</strong></dt>
        </dl>
        —control   may be exerted in studies in many ways: methodological controls are   methodological strategies used to adjust for the effects of confounding   variables, statistical controls are procedures used when potential   confounders cannot be controlled methodologically.
        <dl>
          <dt><strong><a name="Control-Groups" id="Control-Groups"></a>Control Groups</strong></dt>
        </dl>
        —in   experimental or quasi-experimental designs, individuals who do have the   condition of interest e.g., have not been identified as drug abusers or   not exposed to a stimuli are selected and assigned to a control group.    The control group should be as similar as possible to cases in the   experimental condition.  Control groups may be compared with the   experimental groups to determine the effects of the experimental   variable.
        <dl>
          <dt><strong><a name="Controls" id="Controls"></a>Controls</strong></dt>
        </dl>
        —in experimental or quasi-experimental designs,&quot;controls&quot; are cases who fall into the control group.
        <p>—procedures used to reduce or eliminate the effect of possibly   confounding variables on the dependent variable in a study.  Controls   may be experimental procedures or statistical procedures.</p>
        <dl>
          <dt><strong><a name="Convenience-Sampling" id="Convenience-Sampling"></a>Convenience Sampling</strong></dt>
        </dl>
        —recruiting   individuals as they come to a clinic, a university classroom, or some   other place for the sole reason that the investigator has access to   those individuals—i.e., The strategies are&quot;convenient.&quot;  These methods   of sampling will almost assuredly yield a biased sample; the results   from such a study will likely not be generalizable to other populations.
        <dl>
          <dt><strong><a name="Convergent" id="Convergent"></a>Convergent</strong></dt>
        </dl>
        —a   type of validity demonstrated when a scale should conceptually be and   actually is highly correlated with other scales that purportedly measure   either the same or a similar construct.
        <p>—for example, different measures of a concept such as anxiety should   be correlated with other existing measures of anxiety, and to a lesser   extent with measures of other types of psychological affect such as   depression. </p>
        <p>Also, a scale of anxiety should be inversely related to a measure of   life satisfaction because the two scales are conceptually opposite. </p>
        <dl>
          <dt><strong><a name="Correlation" id="Correlation"></a>Correlation</strong></dt>
        </dl>
        —a   commonly used measure of association which measures the strength of   association between two variables. An example is the Pearson   product-moment correlation coefficient.
        <dl>
          <dt><strong><a name="Counterbalance" id="Counterbalance"></a>Counterbalance</strong></dt>
        </dl>
        —in   counterbalancing, some items are worded in a negative manner and others   in a positive way.  Counterbalancing helps reduce the influence of   subjects who use a response set.
        <p>—to ensure that a response set does not influence the scores on a   given measure an item such as&quot;I feel sad&quot; can be followed by an item&quot;I   feel happy&quot;. </p>
        <dl>
          <dt><strong><a name="Criterion-Validity" id="Criterion-Validity"></a>Criterion Validity</strong></dt>
        </dl>
        —when   a scale is developed experts may be asked to classify a group of   subjects as having a condition or not having the condition, and the   scale should agree with a high level of accuracy with the   classifications by the experts.  With a measure of anxiety,   psychiatrists or psychologists may be asked to evaluate a group of   patients to categorize those with anxiety disorders; the group   identified as having some type of anxiety disorder should have higher   scores on the measure that is being assessed than the individuals rated   as not having an anxiety disorder.
        <dl>
          <dt><strong><a name="Cross-Sectional" id="Cross-Sectional"></a>Cross Sectional</strong></dt>
        </dl>
        —a   typical example of cross-sectional study is a community survey. Studies   of the incidence of a disease might include collecting serologic data   to determine individuals who have been exposed to HIV (Human   Immunodeficiency Virus).  For information on prevalence of a given   behavior, a cross-sectional study might be conducted to identify the   percentage of the population who reports illicit drug usage or patterns   of heavy consumption of alcohol.
        <dl>
          <dt><strong><a name="Data" id="Data"></a>Data</strong></dt>
        </dl>
        —the information   gathered in a study.  Note that&quot;data&quot; is plural.  The singular   is&quot;datum.&quot;  But one rarely encounters a single datum.
        <dl>
          <dt><strong><a name="Data-Collection" id="Data-Collection"></a>Data Collection</strong></dt>
        </dl>
        —the process and procedures used to obtain data in a study.
        <dl>
          <dt><strong><a name="Data Entry" id="Data Entry"></a>Data Entry</strong></dt>
        </dl>
        —the   process of recording data obtained in a study in some manner, ranging   from paper and pencil recording to directly entering data into a   computer using a keyboard to direct monitoring of electronic instruments   with a computer.
        <dl>
          <dt><strong><a name="Demographic-Data" id="Demographic-Data"></a>Demographic Data</strong></dt>
        </dl>
        —demographic data refer to data such as age and sex.
        <dl>
          <dt><strong><a name="Dependence" id="Dependence"></a>Dependence</strong></dt>
        </dl>
        —there   is a relationship of dependence between variables when the values of   one of the variables depends on or is affected by the value of the   other.
        <dl>
          <dt><strong><a name="Dependent-Variables" id="Dependent-Variables"></a>Dependent Variables</strong></dt>
        </dl>
        —technically,   the variable that is thought to be influenced by the effects of other   variables, called independent variables. The dependent variable is also   sometimes called the criterion variable.
        <p>Most typically, the dependent variable is the one of interest in a   study, such as the outcome variable in a study of treatment efficacy.</p>
        <dl>
          <dt><strong><a name="Design-Effects" id="Design-Effects"></a>Design Effects</strong></dt>
        </dl>
        —the   design effect is a ratio, typically ranging between approximately 1.2   and .8 reflecting the ratio of the standard errors of estimates of means   or totals for cluster or stratified samples relative to the comparable   standard errors which would be obtained in a simple random sample.
        <dl>
          <dt><strong><a name="Dimensionality" id="Dimensionality"></a>Dimensionality</strong></dt>
        </dl>
        —Complex concepts may have several dimensions.  Dimensionality refers to the number of dimensions of a concept.
        <dl>
          <dt><strong><a name="Discriminant" id="Discriminant"></a>Discriminant</strong></dt>
        </dl>
        —discriminant   validity is established when a measure of a concept is found to not   correlate with other variables measuring other concepts which should not   logically be related to the concept of interest.  For example, a   measure of frequency of drug use displays discriminant validity if it   does not correlate with measures of other concepts with which it should   not be related.
        <dl>
          <dt><strong><a name="Discriminant-Function-Analysis" id="Discriminant-Function-Analysis"></a>Discriminant Function Analysis</strong></dt>
        </dl>
        —a   statistical procedure seeking to predict which category of some   categorical variable cases will fall into using a linear additive   combination of predictor variables.
        <dl>
          <dt><strong><a name="Descriptive-Study" id="Descriptive-Study"></a>Descriptive Study</strong></dt>
        </dl>
        —the characteristics of the population are reported and no hypothesis is tested.
        <dl>
          <dt><strong><a name="Dose-Response-Relationships" id="Dose-Response-Relationships"></a>Dose-Response Relationships</strong></dt>
        </dl>
        —the   relationship between varying levels of some suspected cause and its   effect.  For example, if smoking causes lung cancer, we would expect   that smoking more cigarettes should increase the occurrence of lung   cancer.
        <dl>
          <dt><strong><a name="Double-Blind-Studies" id="Double-Blind-Studies"></a>Double Blind Studies</strong></dt>
        </dl>
        —neither   the researcher nor the subject knows the subject's treatment status.    Double blind designs are very often associated with clinical trials.
        <dl>
          <dt><strong><a name="Effect-Size" id="Effect-Size"></a>Effect Size</strong></dt>
        </dl>
        —effect   size refers to the size of an&quot;effect&quot; to be detected by some   statistical analysis.  For example, an effect might be the difference   between two means or the size of a correlation coefficient.  Effect size   must often be estimated to predict the sample size needed for an   analysis.
        <dl>
          <dt><strong><a name="Empirically-Derived-Factor" id="Empirically-Derived-Factor"></a>Empirically Derived Factor</strong></dt>
        </dl>
        —empirically   derived factors are factors based on an empirical analysis. These may   be contrasted with theoretically derived factors, which are based upon a   priori theories rather than empirical data.
        <dl>
          <dt><strong><a name="Empirical-Studies" id="Empirical-Studies"></a>Empirical Studies</strong></dt>
        </dl>
        —a   study in which a hypothesis is tested.  These investigations differ   from descriptive studies in which only prevalence rates or univariate   statistics (mean, median, standard deviation, etc.) are provided.
        <dl>
          <dt><strong><a name="Environmental-Factors" id="Environmental-Factors"></a>Environmental Factors</strong></dt>
        </dl>
        —environmental   factors may include the social environment, such as community size, or   the physical environment, such as climate or weather.
        <dl>
          <dt><strong><a name="Epidemiology" id="Epidemiology"></a>Epidemiology</strong></dt>
        </dl>
        —the study of the distribution and determinants of disease in populations.
        <dl>
          <dt><strong><a name="Error" id="Error"></a>Error</strong></dt>
        </dl>
        —two types of   error which need to be distinguished are random error which is subject   to the laws of probability and can be estimated and handled   statistically; and systematic error or bias which is not subject to the   laws of probability and can not be estimated or handled statistically.
        <dl>
          <dt><strong><a name="Measurement-Error" id="Measurement-Error"></a>Measurement Error</strong></dt>
        </dl>
        —two   sources of error that occur in virtually every research project is   caused by the instrument itself (e.g., the items are ambiguously   worded—ambiguous to some subjects at least—or the response categories   are inappropriate) or the subject (e.g., items were misread, problems of   memory).
        <dl>
          <dt><strong><a name="Ethical-Concerns" id="Ethical-Concerns"></a>Ethical Concerns</strong></dt>
        </dl>
        —factors   which must be taken into account when conducting studies. These   concerns include the risks to which subjects may be exposed, whether a   debriefing after the study is appropriate, can and should anonymity or   confidentiality be preserved?
        <dl>
          <dt><strong><a name="Ethnicity" id="Ethnicity"></a>Ethnicity</strong></dt>
        </dl>
        —religious,   national, and other cultural characteristics often used to distinguish   groups of people in a society, often including race.
        <dl>
          <dt><strong><a name="Exclusionary-Criteria" id="Exclusionary-Criteria"></a>Exclusionary Criteria</strong></dt>
        </dl>
        —in   study of the effects of a single moderate dose an illicit drug on   cognitive functioning, the inclusionary criteria for subjects might be:    1) between the ages of 12 and 18 (an age arbitrarily chosen, and for   this example, in which the risk of using this drug is highest), 2) of at   least a normal level of cognitive ability, and 3) male (because males   are much more likely to use the imaginary drug in question).
        <p>The exclusionary criteria could be 1) not having been unconscious for   more than 7 minutes after a trauma to the head (to eliminate the   possibility of otherwise latent organic damages confounding the results)   and 2) no history of drug abuse (to rule out the possibility that   chronic drug use exacerbates or magnifies the effects from an acute   dosage of the drug).  Thus, the study sample should be selected based on   rigorous specific criteria, otherwise the results may not replicable by   other researchers.</p>
        <dl>
          <dt><strong><a name="Experimenter-Expectancy-Effects" id="Experimenter-Expectancy-Effects"></a>Experimenter Expectancy Effects</strong></dt>
        </dl>
        —when   experimenters know whether cases are in the experimental group or the   control group, there is the possibility this will influence their   perceptions of and interactions with those people, and in the process,   possibly bias the outcome of the study.  A common strategy to eliminate   these effects is to blind experimenters so they don't know the condition   subjects are in (when possible).
        <dl>
          <dt><strong><a name="Experimental-Designs" id="Experimental-Designs"></a>Experimental Designs</strong></dt>
        </dl>
        —studies intended to test causal relationships in a controlled setting.
        <dl>
          <dt><strong><a name="Experimenter-Bias" id="Experimenter-Bias"></a>Experimenter Bias</strong></dt>
        </dl>
        —systematic error inadvertently introduced into an experiment by the experimenter.
        <dl>
          <dt><strong><a name="Expert-Ratings" id="Expert-Ratings"></a>Expert Ratings</strong></dt>
        </dl>
        —expert   ratings are obtained by asking people knowledgeable in some area to   make judgments or perform some task.  Those judgments may then be used   as a standard against which to evaluate some scale or research   procedure.
        <dl>
          <dt><strong><a name="External" id="External"></a>External</strong></dt>
        </dl>
        —to what extent are the results generalizable to some broader population?
        <dl>
          <dt><strong><a name="Face-Validity" id="Face-Validity"></a>Face Validity</strong></dt>
        </dl>
        —face   validity refers to whether measures or items appear&quot;on the face of  it&quot;   to be reasonable measures of the concepts they claim to be measuring.
        <p>For example, if a scale claims to measure reasons for using drugs,   does each item in the scale, when examined by knowledgeable people,   appear to be a reasonable measure of that concept?</p>
        <dl>
          <dt><strong><a name="Face-To-Face-Interview" id="Face-To-Face-Interview"></a>Face-To-Face Interview</strong></dt>
        </dl>
        —an   interview which takes place with people in physical proximity to one   another, as opposed to an interview over the phone or a mailed   questionnaire.
        <dl>
          <dt><strong><a name="Factor-Analysis" id="Factor-Analysis"></a>Factor Analysis</strong></dt>
        </dl>
        —a   form of statistical analysis which can be used to attempt to  identify   underlying concepts or factors measured by observed variables.
        <dl>
          <dt><strong><a name="Fair-Coin" id="Fair-Coin"></a>Fair Coin</strong></dt>
        </dl>
        —one in which heads and tails have an equal probability of occurring on any given toss.
        <dl>
          <dt><strong><a name="Fishers-Exact-Test" id="Fishers-Exact-Test"></a>Fisher's Exact Test</strong></dt>
        </dl>
        —a nonparametric test of equality of proportions in two different populations for R (row) by C (column) contingency tables.
        <dl>
          <dt><strong><a name="Gender-Ratio" id="Gender-Ratio"></a>Gender Ratio</strong></dt>
        </dl>
        —the ratio of males to females in a sample or population
        <dl>
          <dt><strong><a name="Generalizable Results" id="Generalizable Results"></a>Generalizable Results</strong></dt>
        </dl>
        —the results obtained in the study would be expected to be similar to other samples drawn from the target population.
        <dl>
          <dt><strong><a name="Hypothesis" id="Hypothesis"></a>Hypothesis</strong></dt>
        </dl>
        —the research question that is tested in a scientific study.
        <p>—a one-tailed hypothesis is one in which a particular relationship is   expected.  With all other factors' being equal and compared with a two   tailed hypothesis, testing a one tailed hypothesis required a fewer   number of subjects.  However, the calculation of statistical power   should be based on a two tailed hypothesis. </p>
        <p>—a two-tailed hypothesis is one in which an effect is expected, but the direction of the relationship is not known. </p>
        <p>—an example of a one tailed hypothesis is that males use drugs more   often than females.  That is, a definite relationship is expected.  For a   two tailed hypothesis, the direction of the data cannot be anticipated   with any certainty—intervention A is different from intervention B in   terms of efficacy, but until the data are analyzed, which is better is   not known.</p>
        <dl>
          <dt><strong><a name="Incidence" id="Incidence"></a>Incidence</strong></dt>
        </dl>
        —the   proportion of new cases during some specific period of time.  For   example, a 10% incidence of drug abuse in a given population during a   year would mean that 10% of the people did not abuse drugs at the   beginning of the year, but began abusing drugs during that year.
        <dl>
          <dt><strong><a name="Inclusionary-Criteria" id="Inclusionary-Criteria"></a>Inclusionary Criteria</strong></dt>
        </dl>
        —characteristics that make the person eligible for the study.
        <p>—For example, in a study of the acute effects of a single moderate   dose that an illicit drug has on cognitive functioning, the inclusionary   criteria for subjects might be:  1) between the ages of 12 and 18 (an   age arbitrarily chosen, and for this example, in which the risk of using   this drug is highest), 2) of at least a normal level of cognitive   ability, and 3) male (because males are much more likely to use the   imaginary drug in question). </p>
        <p>—The exclusionary criteria could be 1) not having been unconscious   for more than 7 minutes after a trauma to the head (to eliminate the   possibility of otherwise latent organic damages confounding the results)   and 2) no history of drug abuse (to rule out the possibility that   chronic drug use exacerbates or magnifies the effects from an acute   dosage of the drug).  Thus, the study sample should be selected based on   rigorous specific criteria, otherwise the results may not be replicable   by other researchers.</p>
        <dl>
          <dt><strong><a name="Independence" id="Independence"></a>Independence</strong></dt>
        </dl>
        —variables are independent when they are neither causally related nor the variables correlate with one another.
        <dl>
          <dt><strong><a name="Independent Variables" id="Independent Variables"></a>Independent Variables</strong></dt>
        </dl>
        —variables are independent when they are neither causally related nor the variables correlate with one another.
        <dl>
          <dt><strong><a name="Independent Samples" id="Independent Samples"></a>Independent Samples</strong></dt>
        </dl>
        —independent   samples include cases which are unrelated to one another. For example, a   sample of one person each from many different households would be an   independent sample.  However, samples where the same people were   examined at different points in time could not be considered to be   independent samples.  For some purposes, sampling people in the same   household might raise questions about whether the samples were   independent.
        <dl>
          <dt><strong><a name="Informed Consent" id="Informed Consent"></a>Informed Consent</strong></dt>
        </dl>
        —informed   consent requires that subjects in an experiment or study be given   sufficient information about what will be required of them to make   an&quot;informed&quot; judgment about whether they wish to participate.  Without   adequate information, consent is uninformed.  Informed consent is one of   the common strategies used in much research to assure that human   subjects are treated ethically.
        <dl>
          <dt><strong><a name="Instruments" id="Instruments"></a>Instruments</strong></dt>
        </dl>
        —a scale or measurement device used in research.  For example, questionnaires are often called instruments.
        <dl>
          <dt><strong><a name="Inter-Rater" id="Inter-Rater"></a>Inter-Rater</strong></dt>
        </dl>
        —A   form of reliability.  The evaluations of two individuals who have rated   same occurrences (perhaps on videotape or in vivo) or records are   compared; high agreement between raters indicates good reliability.
        <dl>
          <dt><strong><a name="Interrater-Reliability" id="Interrater-Reliability"></a>Interrater Reliability</strong></dt>
        </dl>
        —A   form of reliability.  The evaluations of two individuals who have rated   same occurrences (perhaps on videotape or in vivo) or records are   compared; high agreement between raters indicates good reliability.
        <dl>
          <dt><strong><a name="Internal-Consistency" id="Internal-Consistency"></a>Internal Consistency</strong></dt>
        </dl>
        —an   obvious assumption of having a multiple item instrument is that the   items are all related to the same construct; therefore, the items should   be highly correlated with one another.  An early method of assessing   the homogeneity among items was to split arbitrarily the scale into two   halves—very often the items appearing in the first half were grouped   against the last half of the items (called top/bottom reliability);   sometimes odd numbered items were grouped against the even numbered   items (called odd/even reliability).  Scores were generated for each   group of items by summing the values of the items contain in that   particular group.  A correlation coefficient was obtained to estimate   the strength of the relationship between the two groups of items.
        <p>—High correlations, of course, indicated that the two groups of items   were highly related to one another.  This finding provided evidence of   internal consistency, and generally was called split half reliability.    This strategy of assessing internal consistency, however, was based on   the assumption that the manner in which the items were ordered was not   biased.  In more recent research, however, Cronbach's alpha is usually   cited as the index of internal consistency.</p>
        <dl>
          <dt><strong><a name="Interquartile Range" id="Interquartile Range"></a>Interquartile Range</strong></dt>
        </dl>
        —the   difference in scores between the 25th and 75th percentiles in a   distribution.  The interquartile range, sometimes abbreviated as IQR, is   a measure of dispersion.
        <dl>
          <dt><strong><a name="Interval-Data" id="Interval-Data"></a>Interval Data</strong></dt>
        </dl>
        —the   points on an interval scale are much more numerous than on an ordinal   scale—and the increments between the data points are consistent   throughout the scale.  This scale provides more information than ordinal   data and is considered a continuous scale.
        <p>—examples of interval scales include the Fahrenheit scale, calendar dates and scores from various psychosocial tests.</p>
        <dl>
          <dt><strong><a name="Interview" id="Interview"></a>Interview</strong></dt>
        </dl>
        —a   commonly-used method of data collection in which researchers ask   questions of respondents.  Interviews permit following up on ambiguous   answers with additional questions or probes.  Interviews may be face-to-   face or over the phone.
        <dl>
          <dt><strong><a name="Intraclass Correlation" id="Intraclass Correlation"></a>Intraclass Correlation</strong></dt>
        </dl>
        —a   statistic which measures the degree to which variation in an   interval-level dependent variable can be explained or predicted from the   categorical independent variable.  The intraclass correlation   coefficient can be used to assess the magnitude of treatment effects in   analysis of variance.
        <dl>
          <dt><strong><a name="Item" id="Item"></a>Item</strong></dt>
        </dl>
        —typically, a question on a scale.
        <dl>
          <dt><strong><a name="Kuder-Richardson" id="Kuder-Richardson"></a>Kuder-Richardson</strong></dt>
        </dl>
        —a   reliability coefficient for the internal consistency of a scale.   Actually, Kuder and Richardson proposed two different statistics, KR-20   and KR-21.  The numbers refer to the number of the equations in their   original paper.
        <dl>
          <dt><strong><a name="Liberal Level Of Alpha" id="Liberal Level Of Alpha"></a>Liberal Level Of Alpha</strong></dt>
        </dl>
        —alpha   is commonly set at .05.  A more liberal alpha level is one greater than   .05 (such as .10).  It is more liberal because a result is more likely    to be concluded to be significant.
        <dl>
          <dt><strong><a name="Likert-Scales" id="Likert-Scales"></a>Likert Scales</strong></dt>
        </dl>
        —items   or a series of items on which responses can be made on an ordinal scale   ranked from&quot;good&quot; to&quot;bad&quot;,&quot;best&quot; to&quot;worst&quot;,&quot;agree&quot; to &quot;disagree&quot;   or&quot;always&quot; to&quot;never&quot;.
        <dl>
          <dt><strong><a name="Logistic Regression" id="Logistic Regression"></a>Logistic Regression</strong></dt>
        </dl>
        —an   alternative to traditional regression, suitable for when the dependent   variable is dichotomous and when many of the independent variables are   categorical.
        <dl>
          <dt><strong><a name="Longitudinal" id="Longitudinal"></a>Longitudinal</strong></dt>
        </dl>
        —a   study in which data are collected from subjects at two or more points   in time.  Because of the temporal component, longitudinal studies are   more costly than are other study designs in terms of time and money.   However, only longitudinal studies can provide data that demonstrate a   causal relationship.
        <dl>
          <dt><strong><a name="MANOVA" id="MANOVA"></a>MANOVA</strong></dt>
        </dl>
        —multivariate analysis of variance in which more than one dependent variable is considered simultaneously.
        <dl>
          <dt><strong><a name="Mailed-Questionnaires" id="Mailed-Questionnaires"></a>Mailed Questionnaires</strong></dt>
        </dl>
        —questionnaires distributed to potential respondents through the mail.  An alternative to face-to-face or phone interviews.
        <dl>
          <dt><strong><a name="Matching" id="Matching"></a>Matching</strong></dt>
        </dl>
        —groups selected to be similar with regard to specific matching variables.
        <p>—Matching is a strategy sometimes employed in experimental designs to   control for variables which might confound the results.  For example,   in a case-control study of the incidence of drug abuse the researcher   might identify drug abusers then seek out other people to serve as   controls who are similar to the drug abusers in race, sex, and age.</p>
        <p>—For example, when matching on gender, if a female case is admitted   to the study, a female control is also obtained; if matching on age and   gender, if a female case is recruited who is 65 years old, a female   control who is of a similar age, usually within a couple of years, is   obtained. </p>
        <dl>
          <dt><strong><a name="Maturation-effects" id="Maturation-effects"></a>Maturation effects</strong></dt>
        </dl>
        —effects   which take place due to the aging or maturing of the individual during   the study.  For example, studies of changes in teenage drug users during   a three-year long intervention should take into account possible   changes in the subjects due to maturing during that period.  Also,   nature  can&quot;mature&quot; and yield different ratings as they become more   proficient.
        <dl>
          <dt><strong><a name="Mean" id="Mean"></a>Mean</strong></dt>
        </dl>
        —a measure of   central tendency which computes the arithmetic average of a set of   scores.  This measure is commonly used for interval-level data, but is   not suitable for nominal data.
        <dl>
          <dt><strong><a name="Measurement" id="Measurement"></a>Measurement</strong></dt>
        </dl>
        —the   process of assigning summary scores to represent variables in an   analysis.  For example, alienation is often measured by asking   respondents several questions from a scale of items, then computing a   summary score estimating their alienation.
        <dl>
          <dt><strong><a name="Measurement Instrument" id="Measurement Instrument"></a>Measurement Instrument</strong></dt>
        </dl>
        —a   tool used to measure some concept.  For example, questionnaires are   measurement instruments.  So are scales, thermometers, and observational   coding schemes.
        <dl>
          <dt><strong><a name="Median" id="Median"></a>Median</strong></dt>
        </dl>
        —a measure of central tendency identifying the value below which 50% of the cases lie and above which 50% of the cases lie.
        <dl>
          <dt><strong><a name="Memory Bias" id="Memory Bias"></a>Memory Bias</strong></dt>
        </dl>
        —subjects   with a certain characteristics such as a severe medical conditions may   wish to&quot;help&quot; the investigator explain the reason that they have   developed their condition.  Such an attitude may be especially evident   if the subject has knowledge of the purported relationship between the   risk factor in question and his or her condition.  For instance, a   recovering alcoholic who suffers a relapse may blame a major life event   or a series of life events for the relapse.
        <dl>
          <dt><strong><a name="Methods Of Random Assignment" id="Methods Of Random Assignment"></a>Methods Of Random Assignment</strong></dt>
        </dl>
        —random   number generators may suffer a glitch or a propensity to develop   patterns of numbers that may conceivably bias the results.
        <p>Rolling a die may produce a biased sample if the die has pitted   rather than painted dots; when the die is pitted,&quot;6&quot; is most likely to   be rolled because of the additional weight on the opposite side of the   die, the&quot;1&quot;; therefore obtaining a higher percentage of even numbers is   more likely as is higher percentage of high numbers (4, 5 and 6). </p>
        <p>Because group assignment may be based on the result of the odd or   even roll, one group may be overrepresented, possibly presenting   problems in the analysis of the data.   Random telephone dialers provide   biased data for some studies because not all people, particularly   American Indians and some recent immigrants, have telephones.</p>
        <dl>
          <dt><strong><a name="Missing-Data" id="Missing-Data"></a>Missing Data</strong></dt>
        </dl>
        —sources   of missing data are: subjects may find a question offensive or   confusing and decide not to respond to that item; sometimes an entire   page of questions is inadvertently skipped; the person collecting or   coding the data may have been careless; an interview is prematurely   terminated by the subject because of time constraints, or parts of the   questionnaire are mixed with other papers and lost.
        <dl>
          <dt><strong><a name="Missing-Values" id="Missing-Values"></a>Missing Values</strong></dt>
        </dl>
        —variables   having no values assigned for specific cases.  For example, when a   respondent leaves a question blank in a questionnaire, their values for   that variable are missing.  A large proportion of missing values can   wreak havoc on sophisticated statistical analyses.
        <dl>
          <dt><strong><a name="Models" id="Models"></a>Models</strong></dt>
        </dl>
        —theoretical   conceptions of some phenomenon.  Models are sometimes viewed as more   modest theories which may be known to be false in some respects, though   true in important respects and reflecting something interesting about   the phenomenon of interest.  Models are also more likely to be formal or   mathematical, more explicit, and more testable than theories.
        <dl>
          <dt><strong><a name="Morbidity" id="Morbidity"></a>Morbidity</strong></dt>
        </dl>
        —sickness.  Morbidity rates are rates of sickness in a population.
        <dl>
          <dt><strong><a name="Mortality" id="Mortality"></a>Mortality</strong></dt>
        </dl>
        —death.  Mortality rates are rates of death in a population.
        <dl>
          <dt><strong><a name="Multicollinearity" id="Multicollinearity"></a>Multicollinearity</strong></dt>
        </dl>
        —a   condition in which there are high correlations among independent   variables in a regression equation.  Multicollinearity makes it   difficult for computational procedures to estimate parameters, leading   to unstable estimates of regression coefficients and high standard   errors of those estimates.
        <dl>
          <dt><strong><a name="Multidimensional-Concepts" id="Multidimensional-Concepts"></a>Multidimensional Concepts</strong></dt>
        </dl>
        —concepts   having two or more distinct, separable components or facets. For   example, the general concept of alienation may include alienation from   family, from work, from country.
        <dl>
          <dt><strong><a name="Multiple Comparisons" id="Multiple Comparisons"></a>Multiple Comparisons</strong></dt>
        </dl>
        —two   or more pairs or combinations of groups are compared to one another in   the same study.  Multiple comparisons require multiple statistical tests   of significance in the same study.  The larger the number of such tests   the greater the possibility of making a Type I error, mistakenly   concluding there is a significant difference when there actually is not.
        <dl>
          <dt><strong><a name="Multiple Regression" id="Multiple Regression"></a>Multiple Regression</strong></dt>
        </dl>
        —a   type of statistical analysis assessing the relationship between a   single continuous, interval-level dependent variable and two or more   independent variables.
        <dl>
          <dt><strong><a name="Multivariate-Analyses" id="Multivariate-Analyses"></a>Multivariate Analyses</strong></dt>
        </dl>
        —advanced   statistical techniques used to assess the relationship of several   variables with the outcome variable.  These relationships are usually   examined in terms of the combined relationship of the independent   variables on the dependent variable and in terms of the relative   association of each independent variable with the dependent variable.    In assessing the relative relationship of the independent variables, the   effects of all of the other independent variables in the model are   statistically partialled out or controlled.
        <p>—An example of an equation (in this case a multiple regression) of a multivariate analysis is: </p>
        <p> TREATMENT OUTCOME= CONSTANT + b1x1 + b2x2 +... + bixi </p>
        <p>where Treatment OUTCOME is a value on a continuous scale, such as a   severity index; b is the slope for x and x is the independent   variable—in the example above, x1 could be SES, x2 would be gender, and   xi (i denotes the final in the series of variables) would contain the   information about whether the subject were in treatment or not.  The   results would show the relationship of each independent   variable—adjusted for the influence of the other variables in the   independent variable list—with treatment outcome, and the strength   (usually noted as R or a Multiple R) of the combined relationship of the   independent variables to the outcome.  R is analogous to r in that   squaring (e.g., to R2) that value will yield an estimate of the variance   explained by the model.  The variance explained may be easier to   understand by knowing if the variance explained were removed, 1-R2 would   remain in the outcome variable.  Thus, if R2=.20, removal of the   variables in the equation, if possible, would leave an outcome variable   with only 80% of its original values.</p>
        <dl>
          <dt><strong><a name="Negative data" id="Negative data"></a>Negative data</strong></dt>
        </dl>
        —data   which do not support the researcher's hypothesis.  For example, if the   researcher hypothesizes a treatment group will display a lower value of   the dependent variable than the control group, but the data support the   opposite conclusion, then those are negative or disconfirming data.
        <dl>
          <dt><strong><a name="Negative-Results" id="Negative-Results"></a>Negative Results</strong></dt>
        </dl>
        —results   which fail to obtain a statistically significant outcome. Negative   results should be accepted without attempts to explain them away.   Knowing clearly what does not work, or why it did not work, is an   important step in the scientific process.
        <dl>
          <dt><strong><a name="Nested" id="Nested"></a>Nested</strong></dt>
        </dl>
        —categories   of one variable are nested within categories of another in an   experimental design when they vary differently within categories of some   other variable.  For example, if an experimental design varies gender   and age, but for males the age categories are &lt;40 and 40 or over,   while for females, the age categories are &lt;30 or 30 and over, then   age is nested within gender in this study.
        <dl>
          <dt><strong><a name="Nominal-Data" id="Nominal-Data"></a>Nominal Data</strong></dt>
        </dl>
        —gender   (male/female), ethnicity (Hispanic, Black, White), source of subject   (urban/rural, school A/school B, etc.), or treatment status   (experimental, control).
        <p>—the values of nominal variables have no natural order (e.g.,cannot   be ranked from&quot;good&quot; to&quot;bad&quot; or&quot;first&quot; to&quot;last&quot;). Thus, nominal   variables are strictly categorical and provide the least amount of   information than any other type of scale.</p>
        <dl>
          <dt><strong><a name="Nonparametric" id="Nonparametric"></a>Nonparametric</strong></dt>
        </dl>
        —tests   that are sometimes called&quot;distribution free methods&quot; of analyzing data.    Unlike parametric tests, nonparametric tests are not based on any   assumption about the distribution of the data.  However, when the data   are parametric, nonparametric tests are usually less powerful (likely to   yield a statistically significant findings when a relationship truly   exists) than are parametric tests.
        <dl>
          <dt><strong><a name="Nonprobability-Sample" id="Nonprobability-Sample"></a>Nonprobability Sample</strong></dt>
        </dl>
        —a   sample in which the probability of inclusion of each case is unknown.   For example, convenience or quota samples which simply take the first n   cases which become available on a street corner are more likely to   sample people who live or work in that neighborhood and who tend to be   walking by during the study, and there is no way of knowing how much   more or less likely any one individual is to be included in the study.
        <dl>
          <dt><strong><a name="Nonresponse-Rate" id="Nonresponse-Rate"></a>Nonresponse Rate</strong></dt>
        </dl>
        —the   rate at which cases approached to participate in a study choose not to   respond.  For example, mailed questionnaires often have much higher   nonresponse rates than face-to-face or phone interviews.
        <dl>
          <dt><strong><a name="Null-Hypothesis" id="Null-Hypothesis"></a>Null Hypothesis</strong></dt>
        </dl>
        —the   hypothesis that there is no relationship between two variables (or no   difference between two means).  The null hypothesis is the alternative   to the hypothesis which you normally hope to support in a study.
        <dl>
          <dt><strong><a name="Objective" id="Objective"></a>Objective</strong></dt>
        </dl>
        —a   measure is objective if different people performing the measurement   procedure would come to the same conclusions.  For example, many   standardized multiple-choice tests administered to national samples of   students are said to be objective because the results are unlikely to be   affected by the school setting in which the test is administered,   unlike GPA, which can mean very different things in different schools.
        <dl>
          <dt><strong><a name="Oblique Rotation" id="Oblique Rotation"></a>Oblique Rotation</strong></dt>
        </dl>
        —a   variant of rotation in factor analysis in which factors are permitted   to become correlated with one another as a result of the rotation.
        <dl>
          <dt><strong><a name="Observational" id="Observational"></a>Observational</strong></dt>
        </dl>
        —observational data are data obtained by watching.
        <dl>
          <dt><strong><a name="One-Tailed" id="One-Tailed"></a>One-Tailed</strong></dt>
        </dl>
        —a   two-tailed hypothesis is one which does not specify direction.  For   example, the hypothesis that a control group will differ from the   experimental group on the dependent variable requires a two-tailed   hypothesis.  In contrast, a one-tailed hypothesis is one which does   specify direction, such as the hypothesis that the control group will   have lower scores on the dependent variable than the experimental group.
        <dl>
          <dt><strong><a name="Open-Ended-Items" id="Open-Ended-Items"></a>Open-Ended Items</strong></dt>
        </dl>
        —the   respondent is provided space on a data collection sheet, usually   directly below the item, to write the reply.  In these items, no   predefined choices are provided and the subject is free to respond in   whatever manner he or she wishes.
        <dl>
          <dt><strong><a name="Ordinal Data" id="Ordinal Data"></a>Ordinal Data</strong></dt>
        </dl>
        —a   variable that has levels that can be classified as categorical data,   but the subgroups have some type of sequence—e.g., from&quot;good&quot; to&quot;bad&quot;   or&quot;first&quot; to&quot;last&quot;.  Because ordinal scales have some gradation in   quality, they usually provide more information about a subject than   the&quot;either/or&quot; classification of nominal scales.  However, the range of   ordinal scales is usually limited—from 2 levels to perhaps 7 or more   levels; the more levels the scale has, the more the data can be   considered continuous data.
        <p>—for example:  a person's condition can be classified as &quot;good,&quot;   &quot;fair,&quot; or &quot;poor.&quot;  Also individuals may respond to a question as either   &quot;strongly agree,&quot; &quot;agree,&quot; &quot;neither agree nor disagree,&quot; &quot;disagree,&quot; or   &quot;strongly disagree.&quot;</p>
        <dl>
          <dt><strong><a name="Orthogonal Rotation" id="Orthogonal Rotation"></a>Orthogonal Rotation</strong></dt>
        </dl>
        —A common form of rotation in factor analysis in which factors must remain orthogonal (i.e., uncorrelated) during rotation.
        <dl>
          <dt><strong><a name="Outcome-Variable" id="Outcome-Variable"></a>Outcome Variable</strong></dt>
        </dl>
        —the   variable of interest in a study.  The outcome variable is typically   thought to be affected by independent variables manipulated in a study.    Outcome variables are also sometimes called dependent variables.
        <dl>
          <dt><strong><a name="Outliers" id="Outliers"></a>Outliers</strong></dt>
        </dl>
        —observations   that unduly influence the results of the study because some individuals   have very high or very low values on a given variable. Outliers are   particularly problematic when using parametric tests of significance   because they rely on means and standard deviations that are skewed by   the outlying scores.
        <dl>
          <dt><strong><a name="Overmatching" id="Overmatching"></a>Overmatching</strong></dt>
        </dl>
        —too many matching variables are used, and finding a comparable control may be difficult or impossible.
        <p>—For example, finding a match would be difficult if a case were an 85   year old man and the criteria on which to match were:  no physical   disabilities, high socioeconomic status, and plays tennis five times a   week.</p>
        <dl>
          <dt><strong><a name="Overreport" id="Overreport"></a>Overreport</strong></dt>
        </dl>
—overreporting occurs when the incidence of some event is reported as   occurring more often than it actually occurs.  For example, crimes might   be overreported by people seeking insurance settlements for crimes   which did not occur.
<dl>
  <dt><strong><a name="p" id="p"></a>p</strong></dt>
</dl>
—indicates the   likelihood that the observed relationship could have been a result of   chance alone.  The value of p is computed based on the test statistic   and the sample size.  p should not really be considered an index of the   magnitude of relationship; this index is the test statistic.
<dl>
  <dt><strong><a name="Paired Data" id="Paired Data"></a>Paired Data</strong></dt>
</dl>
—data in which each individual provides two observations, e.g., these data usually are collected in a longitudinal study.
<dl>
  <dt><strong><a name="Paired-Samples" id="Paired-Samples"></a>Paired Samples</strong></dt>
</dl>
—samples   in groups of two related cases.  For example, studies of twins use   paired samples.  Studies of related husbands and wives are also paired   samples.
<dl>
  <dt><strong><a name="Panel-Studies" id="Panel-Studies"></a>Panel Studies</strong></dt>
</dl>
—studies in which the same individuals are studied at two or more points in time.
<dl>
  <dt><strong><a name="Paper-Pencil-Measures" id="Paper-Pencil-Measures"></a>Paper / Pencil Measures</strong></dt>
</dl>
—generally written questionnaires filled out by participants using paper and pencil.
<dl>
  <dt><strong><a name="Parametric" id="Parametric"></a>Parametric</strong></dt>
</dl>
—statistical   tests in which the distribution of the variables is assumed to be a   normal, bell-shaped curve.  That is, relatively few observations are   found at the extreme low and the extreme high end of the scale with the   highest percentage of people clustering around the average.
<dl>
  <dt><strong><a name="Parsimonious" id="Parsimonious"></a>Parsimonious</strong></dt>
</dl>
—simple.  A parsimonious study is a simple study.
<dl>
  <dt><strong><a name="Path Analysis" id="Path Analysis"></a>Path Analysis</strong></dt>
</dl>
—a   statistical technique for examining correlations to estimate both   direct and indirect causal effects among variables. Path analyses often   involve using a diagram to display hypothesized or estimated causal   effects among variables.
<dl>
  <dt><strong><a name="Payment" id="Payment"></a>Payment</strong></dt>
</dl>
—sometimes studies are paid money or other rewards for participating in a study.
<dl>
  <dt><strong><a name="Peer-Ratings" id="Peer-Ratings"></a>Peer Ratings</strong></dt>
</dl>
—assessments   made by people similar to one another.  For example, the behavior of   one teenage subject might be rated or assessed by other teenagers with   similar backgrounds.
<dl>
  <dt><strong><a name="Pilot Data" id="Pilot Data"></a>Pilot Data</strong></dt>
</dl>
—data collected in a pilot study or preliminary study used to guide the design and conduct of some later study.
<dl>
  <dt><strong><a name="Pilot Study" id="Pilot Study"></a>Pilot Study</strong></dt>
</dl>
—a   preliminary study whose results are typically used primarily to help in   the design (or redesign) of a larger, more ambitious study.
<dl>
  <dt><strong><a name="Placebo" id="Placebo"></a>Placebo</strong></dt>
</dl>
—a subject   is given a treatment that would not be expected to influence the   subject's outcome.  Such subjects are used in a control group.  A   placebo effect is common in clinical trials and occurs when improvement   in the subject's condition is found in the control group.  Because they   receive no actual treatment, the reason that these groups improve is   usually unknown.
<dl>
  <dt><strong><a name="Population" id="Population"></a>Population</strong></dt>
</dl>
—a group of people (or perhaps other entities such as organizations).
<dl>
  <dt><strong><a name="Population-Of-Interest" id="Population-Of-Interest"></a>Population Of Interest</strong></dt>
</dl>
—the   group of people (or other entities such as organizations) to which the   results of a study are to be generalized.  For example, the population   of interest might be high-school aged minority youth in inner cities.
<dl>
  <dt><strong><a name="Power" id="Power"></a>Power</strong></dt>
</dl>
—the   probability of a type II error in a statistical hypothesis test.  Power   is a measure of the likelihood that a study will correctly conclude   there is a significant effect when there is one.
<dl>
  <dt><strong><a name="Power-Calculations" id="Power-Calculations"></a>Power Calculations</strong></dt>
</dl>
—are   used to determine the likelihood of finding a statistically significant   result when a significant relationship actually exists.  Power   calculations are often used, and should be used, to determine the number   of subjects that need to be recruited into the study.  Power   calculations are based on the:
<ul>
  <li>expected magnitude of the relationship</li>
  <li>number of subjects</li>
  <li>expected variability of the data</li>
  <li>level of alpha</li>
  <li>type of hypothesis (one versus two-tailed)</li>
</ul>
<p> Any one of these values can be calculated if the information   from the others is available.  Typically, investigators know:  1) the   expected magnitude of the relationship such as  that found in previous   studies. Although some tendency to be overly optimistic about the   strength of the relationship that would be found in the proposed study   is not unusual among investigators, such optimism is very much ill-   advised; 2) the level of alpha is  usually set at .05; 3) the   variability of the data, e.g., for continuous scales indicated by the   standard deviations; and 4) the direction of the hypothesis, whether it   is one-tailed or two-tailed.</p>
<p> Nothing is worse than to get to the analysis portion of the   study and discover that too few subjects were enrolled in the study, and   no conclusion can be made about whether the hypothesis is supported or   not.</p>
<dl>
  <dt><strong><a name="PPS-Samples" id="PPS-Samples"></a>PPS Samples</strong></dt>
</dl>
—samples   selected so that the probability of selecting any segment of the   population is proportionate to the size of that segment.  (PPS stands   for probability proportionate to size.)  For example, in a study of a   population having 12% minorities and 88% non-minorities, a PPS sample   would end up with a sample composed of 12% minorities and 88%   non-minorities.
<dl>
  <dt><strong><a name="Pretest" id="Pretest"></a>Pretest</strong></dt>
</dl>
—a test   taking place prior to or as a part of the main study.  For example, with   questionnaires, one should usually administer a proposed questionnaire   to a small sample of respondents before the main study in order to   assess whether there are changes which need to be made.  In an   experiment, a pretest is used to measure important dependent variables   for a group before they are subjected to the experimental stimulus.
<dl>
  <dt><strong><a name="Precision" id="Precision"></a>Precision</strong></dt>
</dl>
—estimates   of parameters are more precise if they display less measurement error.    Precision tends to increase as sample size increases and to decrease as   natural variability increases.
<dl>
  <dt><strong><a name="Prevalence" id="Prevalence"></a>Prevalence</strong></dt>
</dl>
—the   percentage of a population displaying a given characteristic or   condition at any one time.  Prevalence describes the extent to which   something is present; incidence describes the rate at which new cases   occur.
<dl>
  <dt><strong><a name="Previously-Constructed-Measures" id="Previously-Constructed-Measures"></a>Previously Constructed Measures</strong></dt>
</dl>
—scales   or instruments already developed and tested by other researchers.  Much   research on drug abuse, for example, makes use of scales constructed by   other researchers which have been validated on similar populations.
<dl>
  <dt><strong><a name="Probability-Samples" id="Probability-Samples"></a>Probability Samples</strong></dt>
</dl>
—e.g.,   a sample obtained in a manner which precludes biased selection by the   researcher as well as self-selection by subjects in the sample. Common   examples include simple random samples and stratified random samples.
<dl>
  <dt><strong><a name="Prospective-Studies" id="Prospective-Studies"></a>Prospective Studies</strong></dt>
</dl>
—a   longitudinal study designed to follow subjects until a specific outcome   occurs or a period of time expires.  Such a study of course, requires   two or more observations from each subject and must begin before the   outcome occurs.
<p>—An example of a prospective study is a drug abuse treatment program   in which success is defined as abstinence for two years after treatment;   the investigators maintain contact with such subjects for a period   until two years or until evidence is obtained that the subject has not   been abstinent.  Thus, at the end of the second year, all subjects can   be defined as&quot;successes&quot; or&quot;failures.&quot;</p>
<dl>
  <dt><strong><a name="Purposive-Sampling" id="Purposive-Sampling"></a>Purposive Sampling</strong></dt>
</dl>
—sampling   directed by an objective or purpose.  For example, a study of the   legislative process which led to the passage of a specific law might   include a purposive sample of legislators who were particularly active   in that process.  Here, members of the sample are selected for their   unusual knowledge or relevance to the study.
<dl>
  <dt><strong><a name="Quota-Sampling" id="Quota-Sampling"></a>Quota Sampling</strong></dt>
</dl>
—a   nonprobability sample in which strata are first identified and then a   specific number (quota) of cases is selected from each stratum.  Such a   sample is not a probability sample because there are no constraints   determining how subjects are to be selected other than that a certain   number be obtained.
<dl>
  <dt><strong><a name="Random" id="Random"></a>Random</strong></dt>
</dl>
—a process   is random if each possible outcome has the same chance of occurring.    For example, a fair coin when tossed would have the same probability of   obtaining heads (.5) and tails (.5).
<dl>
  <dt><strong><a name="Random-Error" id="Random-Error"></a>Random Error</strong></dt>
</dl>
—variations in a score or result which display no systematic bias.
<dl>
  <dt><strong><a name="Random-Assignment" id="Random-Assignment"></a>Random Assignment</strong></dt>
</dl>
—in   an experimental design such as in clinical trial, each subject entering   the study has an equal chance of being assigned into one of the   treatment group.
<dl>
  <dt><strong><a name="Random-Selection" id="Random-Selection"></a>Random Selection</strong></dt>
</dl>
—each   sampling unit has an equal chance of being selected for inclusion in   the study.  Usually an individual subject is a&quot;sampling unit,&quot; but the   unit can be a family, organization, or some other group of people.
<dl>
  <dt><strong><a name="Randomization" id="Randomization"></a>Randomization</strong></dt>
</dl>
—a   method of selecting subjects for a study or assigning subjects to   conditions in the study in which each case has the same probability of   being selected or assigned.
<dl>
  <dt><strong><a name="Randomized" id="Randomized"></a>Randomized</strong></dt>
</dl>
—a   study in which subjects are selected and assigned so that each case has   the same probability of selection or assignment as any other case.
<dl>
  <dt><strong><a name="Range Of Responses" id="Range Of Responses"></a>Range Of Responses</strong></dt>
</dl>
—the   difference between the highest and lowest scores obtained for   responses.  Range is a measure of dispersion estimating the extent of   variation in responses.
<dl>
  <dt><strong><a name="Rank Order" id="Rank Order"></a>Rank Order</strong></dt>
</dl>
—the   sequential position of an object or item when all such objects or items   have been ordered from smallest to largest.  For example, scores on   objective tests of academic achievement often report rank orders or   percentile scores for individuals.
<dl>
  <dt><strong><a name="Ranked-Data" id="Ranked-Data"></a>Ranked Data</strong></dt>
</dl>
—the   highest observation is assigned a&quot;1&quot; the next highest a&quot;2&quot; and so on;   of course, the opposite scoring may also be performed—the lowest score   receives a&quot;1&quot; the next lowest a&quot;2&quot; etc.  Data are usually ranked because   an outlier is influencing the distribution of one or more variables   which in turn will probably affect the results of a parametric   statistical test.  In the event that two or more observations have the   same score, the median rank of the ties is used for all of the tied   observations.  For instance, if the highest score receives a&quot;1,&quot; and   there are two individuals with the second highest score, the tied   observations would each receive a score of&quot;2.5&quot;—if there were three tied   with the second highest score, they would each receive a value of&quot;3.0.&quot;
<dl>
  <dt><strong><a name="Rare-Exposures" id="Rare-Exposures"></a>Rare Exposures</strong></dt>
</dl>
—exposures   which occur infrequently.  For example, most people are rarely exposed   to dangerously high radiation levels.  Studies of such rare exposures to   risk often require special design strategies or sampling strategies to   permit the studies to be performed economically.
<dl>
  <dt><strong><a name="Ratio-Scales" id="Ratio-Scales"></a>Ratio Scales</strong></dt>
</dl>
—ratio   scales provide the most information of all the levels of measurement,   including all the information provided by interval scales plus a ratio   scale has a true zero point.
<p>—Examples include the Kelvin scale measures of distance, and timed events.</p>
<dl>
  <dt><strong><a name="Readability" id="Readability"></a>Readability</strong></dt>
</dl>
—an   index of the level of education required to read and understand the   written components of a measurement instrument.  Readability should be   considered when using instruments on populations likely to have little   or no formal schooling.
<dl>
  <dt><strong><a name="Refusals" id="Refusals"></a>Refusals</strong></dt>
</dl>
—refusals   are people who refuse to participate in a study.  Steps should be taken   to keep the refusal rate as low as possible while still meeting ethical   standards for research.
<dl>
  <dt><strong><a name="Regression" id="Regression"></a>Regression</strong></dt>
</dl>
—a   statistical analysis procedure assessing the relationship between a   continuous, interval-level dependent variable and one or more other   variables.
<dl>
  <dt><strong><a name="Relationship" id="Relationship"></a>Relationship</strong></dt>
</dl>
—a   causal or covariational connection between two or more variables.  For   example, two variables may have high correlations or one may cause the   other.
<dl>
  <dt><strong><a name="Reliability" id="Reliability"></a>Reliability</strong></dt>
</dl>
—can   be described as the stability, consistency, or precision of an   instrument.  Reliability may be demonstrated in different ways,   depending on the nature of the measure.  Types of reliability include   internal consistency, alternate form, test-retest, and interrater   reliability.
<dl>
  <dt><strong><a name="Reliability/Validity" id="Reliability/Validity"></a>Reliability/Validity</strong></dt>
</dl>
—measurement   instruments should be assessed for reliability (consistency of response   over time, across raters, and across circumstances) and validity (the   extent to which the instrument measures what it claims to measure).
<dl>
  <dt><strong><a name="Repeated-Measures-Designs" id="Repeated-Measures-Designs"></a>Repeated Measures Designs</strong></dt>
</dl>
—   are used in experiments in which each of n subjects is tested under   each of k conditions.  This is analogous to comparing pre- and post-test   results using a paired t-test.  Such designs are appealing in that they   allow the experimenter to control for systematic differences among   subjects and to reduce the total number of subjects required in the   experiments (Although, some caution should be exercised when adjusting   sample size.).
<p>Care must be taken in randomizing the tests whenever possible.  In   experiments such as those involving variables such as experience or   learning this may not be possible, but repeated measures designs are an   appropriate choice.</p>
<p>Repeated measures designs may be analyzed by ANOVA.  The difficulty   in analysis arises from assumptions about the distribution and   dependency among variables, and the selection of an appropriate error   term to be used in testing significance.  This is particularly true if   the experiment is a multifactorial one.  The technique for the ANOVA can   be based on either univariate or multivariate analysis, depending on   assumptions about the data.  Neither is necessarily superior under all   circumstances.  Computer packages such as SAS, SPSS, and BMDP can handle   complex designs as either univariate or multivariate ANOVA.  However,   care must be taken in selecting the way in which the data are entered   and in specifying the model to be tested. </p>
<p>When a repeated measures design is to be used, it is important to   specify the corresponding analysis.  A standard crossed ANOVA would be   inappropriate and might call into question the researcher's   understanding of the design.</p>
<dl>
  <dt><strong><a name="Response-set" id="Response-set"></a>Response set</strong></dt>
</dl>
—a   response set is a tendency to respond to all items in a similar manner,   without regard for their content.  For example, someone might mark&quot;yes&quot;   to all items in a questionnaire without regard to their content.
<dl>
  <dt><strong><a name="SES" id="SES"></a>SES</strong></dt>
</dl>
—SES is   socioeconomic status.  This is a commonly-used concept in the social   sciences.  There are many ways to measure SES.  Most commonly it is   measured by a combination of measures of educational status,   occupational status, and income.
<dl>
  <dt><strong><a name="Retrospective" id="Retrospective"></a>Retrospective</strong></dt>
</dl>
—a   retrospective study is one in which a group of cases having a condition   are compared to other cases not having the condition.  Such studies are   also sometimes called case-control studies.
<dl>
  <dt><strong><a name="Retrospective Study" id="Retrospective Study"></a>Retrospective Study</strong></dt>
</dl>
—a   retrospective study is one in which a group of cases having a condition   are compared to other cases not having the condition.  Such studies are   also sometimes called case-control studies.
<dl>
  <dt><strong><a name="Research-Risks" id="Research-Risks"></a>Research Risks</strong></dt>
</dl>
—research   studies may place subjects at risk in one or more ways, including risk   of exposure of their identity and risk of suffering adverse consequences   from the treatment.  Potential risks for human subjects (and animal   subjects) must be minimized, assessed, and explained to human subjects   as part of obtaining informed consent.
<dl>
  <dt><strong><a name="Risk" id="Risk"></a>Risk</strong></dt>
</dl>
—the probability   of occurrence of some event.  Risk is typically associated with some   undesirable outcome, while the more general term, probability, is   usually used to characterize both positive and negative outcomes.
<dl>
  <dt><strong><a name="Risk Factors" id="Risk Factors"></a>Risk Factors</strong></dt>
</dl>
—factors   associated with an increased risk of some event occurring are called   risk factors.  A few risk factors for heart disease, for example, are   obesity, smoking, and a family history of heart disease.
<dl>
  <dt><strong><a name="Rotation" id="Rotation"></a>Rotation</strong></dt>
</dl>
—rotation   is used in factor analysis to produce factors which are mathematically   equivalent to those initially extracted but more easily interpreted.
<dl>
  <dt><strong><a name="Sample" id="Sample"></a>Sample</strong></dt>
</dl>
—a sample is a subset of cases from a population.
<dl>
  <dt><strong><a name="Sample-Size" id="Sample-Size"></a>Sample Size</strong></dt>
</dl>
—sample   size is defined as the number of cases examined in a study.  Sample   size is one of the most important aspects of a research study and   requires justification.  Sample size should be selected to be large   enough to conclude that substantively significant effects are   statistically significant.
<dl>
  <dt><strong><a name="Sampling Fraction" id="Sampling Fraction"></a>Sampling Fraction</strong></dt>
</dl>
—the   sampling fraction is the fraction of cases in a population included in a   sample.  For example, if the sampling fraction is 1/10 then one tenth   of the people in the population are included in the sample.
<dl>
  <dt><strong><a name="Sampling-Frame" id="Sampling-Frame"></a>Sampling Frame</strong></dt>
</dl>
—a   sampling frame provides a means to select cases from a population.   Common examples of sampling frames are lists such as telephone   directories or maps.  A sampling frame should have the property that   every population element has some chance of being included in the sample   by the selection procedure used.
<dl>
  <dt><strong><a name="Sampling-Unit" id="Sampling-Unit"></a>Sampling Unit</strong></dt>
</dl>
—the   units in a sampling frame are called sampling units.  For example,   phone directories usually list households (or companies), so the   sampling unit using a phone directory is a household.  In multistage   samples, successive frames typically use different units.  For example,   at an early stage, the sampling unit may be counties, later the unit may   be census tracts, still later, households, and finally, individuals.
<dl>
  <dt><strong><a name="Scatter Plot" id="Scatter Plot"></a>Scatter Plot</strong></dt>
</dl>
—a   diagram in which cases are plotted as points in a Cartesian coordinate   system (X and Y axes) used to display the relationship between two   variables.  Because one can easily see the value for each of the two   variables for each case, the scatter plot helps make apparent the   covariation between the two variables.
<dl>
  <dt><strong><a name="Self Selection Bias" id="Self Selection Bias"></a>Self Selection Bias</strong></dt>
</dl>
—selection   bias occurs when groups to be compared in a study differed before any   experimental manipulation took place.  For example, a study comparing   people who choose to participate in a drug treatment program with other   people who choose not to participate, would be suspect because it is   quite possible—even likely—that people choosing to participate were   already different in important ways from those who choose not to   participate.
<dl>
  <dt><strong><a name="Selection-Criteria" id="Selection-Criteria"></a>Selection Criteria</strong></dt>
</dl>
—selection   criteria are characteristics which must be present in cases in order   for them to be selected for participation in a study.  In treatment   studies, for example, it is common to restrict participation in a study   to cases which are part of a target population expected to receive   greatest benefit from some intervention.  It is also common to exclude   from the study cases which may have some confounding condition, such as a   related disease, which might cause those cases to respond in some   unusual way to the treatment.
<dl>
  <dt><strong><a name="Self-Report" id="Self-Report"></a>Self-Report</strong></dt>
</dl>
—information obtained directly from the subject.  These data can be obtained from paper/pencil tests, interviews, surveys, etc.
<dl>
  <dt><strong><a name="Sensitivity" id="Sensitivity"></a>Sensitivity</strong></dt>
</dl>
—the   instrument's ability to identify individuals who have a certain   characteristic, such as a particular psychopathology or a physical   illness. As sensitivity increases, specificity decreases.
<p><em>Example:</em></p>
<p>—assume that 20% of a sample coming to a clinic has a drug abuse   problem.  Rather than using lengthy and more costly interviews to   classify individuals, an investigator decides to create a screening   instrument that can be administered quickly and inexpensively to   identify people with drug problems.  Technically and in the most   blatantly ludicrous scenario, the researcher could choose the items at   random—regardless of the content of the items—administer the test to the   sample, and declare that any score on the test indicates a possible   drug dependency.  Such a scale would have 100% sensitivity—all of the   drug abusers would be correctly classified—but have very poor   specificity, with none of the nonabusers identified.</p>
<p>Of course, the researcher could correctly identify 100% of the   nonabusers and 80% of the entire sample if any score on the test was   proposed to indicate no drug abuse problem.  Of course, neither strategy   in</p>
<p>the above example is recommended.  Yet, these types of problems exist   when an investigator tries to develop an instrument with acceptable   levels of sensitivity and specificity.  As sensitivity increases,   specificity almost always decreases because of variability across   individuals on the items that are used to make the classifications.    That is, some individuals who are normal will score high enough on an   instrument to be incorrectly classified; other people who are should be   classified as having a certain characteristics will score low enough   that they will be classified as&quot;normal.&quot;   Typically when such a scale   is developed, sensitivity and specificity are demonstrated with an   external criterion.  That is, some other information is used to assess   how well the scale performs.  In the above example of drug abuse, an   experienced clinician might be used to classify individuals after an   interview, or archival records such as arrest records, employment   history, or self-reported drug involvement might be used to evaluate the   efficacy of the proposed scale.</p>
<dl>
  <dt><strong><a name="Significant" id="Significant"></a>Significant</strong></dt>
</dl>
—a   result is significant if it is unlikely to have occurred chance.  Tests   of statistical significance compare observed data with distributions of   outcomes which would be expected by chance from some process to see how   likely the observed response is to have resulted from the hypothesized   process.  For example, to say that there is a significant difference   between the experimental and control groups is to say the difference   which was observed is unlikely to have occurred by chance if the two   groups actually were not different.
<dl>
  <dt><strong><a name="Simple-Linear-Regression" id="Simple-Linear-Regression"></a>Simple Linear Regression</strong></dt>
</dl>
—regression   in which relationships between the dependent variable and independent   variables are assumed to be linear—i.e., they can be expressed as the   slope and intercept of a straight line.
<dl>
  <dt><strong><a name="Single-Blind Studies" id="Single-Blind Studies"></a>Single-Blind Studies</strong></dt>
</dl>
—either   the researcher or the subject knows the subject's treatment status.  As   a result, the potential for bias exists because the subject may want   to&quot;help&quot; the investigator find a significant result or may respond in a   socially desirable manner.  Further, if the investigator knows the   subject's condition, the experimenter may be biased when recording the   subjects responses.
<dl>
  <dt><strong><a name="Skewness" id="Skewness"></a>Skewness</strong></dt>
</dl>
—skewness   is the extent to which scores are distributed asymmetrically.   Positively skewed distributions have scores with more extreme positive   values than negative ones, and negatively skewed distributions have   scores with more extreme negative scores.
<dl>
  <dt><strong><a name="Snowball-Sampling" id="Snowball-Sampling"></a>Snowball Sampling</strong></dt>
</dl>
—in   a study of drug use among street gangs, the most practical means by   which potential sources of information can be identified may be to   contact a known source who will direct the investigator to other   subjects.
<dl>
  <dt><strong><a name="Socially Desirable Response" id="Socially Desirable Response"></a>Socially Desirable Response</strong></dt>
</dl>
—social   desirability is a bias which may occur when subjects respond in a   manner which is intended to make them look good or be consistent with   norms in a population rather than responding truthfully.  For example,   studies of sexual behavior are often thought to be influenced by   subjects tending to respond in a manner which is more consistent with   population norms than their actual behaviors.
<dl>
  <dt><strong><a name="Specificity" id="Specificity"></a>Specificity</strong></dt>
</dl>
—the ability to classify accurately only those individuals with the characteristics of interest.
<p>—For example, assume that 20% of a sample coming to a clinic has a   drug abuse problem.  Rather than using lengthy and more costly   interviews to classify individuals, an investigator decides to create a   screening instrument that can be administered quickly and inexpensively   to identify people with drug problems.  Technically and in the most   blatantly ludicrous scenario, the researcher could choose the items at   random— regardless of the content of the items—administer the test to   the sample, and declare that any score on the test indicates a possible   drug dependency.  Such a scale would have 100% sensitivity—all of the   drug abusers would be correctly classified—but have very poor   specificity, with none of the nonabusers identified.</p>
<p>Of course, the researcher could correctly identify 100% of the   nonabusers and 80% of the entire sample if any score on the test was   proposed to indicate no drug abuse problem.  Of course, neither strategy   in the above example is recommended.  Yet, these types of problems   exist when an investigator tries to develop an instrument with   acceptable levels of sensitivity and specificity.  As sensitivity   increases, specificity almost always decreases because of variability   across individuals on the items that are used to make the   classifications.  That is, some individuals who are normal will score   high enough on an instrument to be incorrectly classified; other people   who are should be classified as having a certain characteristics will   score low enough that they will be classified as&quot;normal.&quot;   Typically   when such a scale is developed, sensitivity and specificity are   demonstrated with an external criterion.  That is, some other   information is used to assess how well the scale performs.  In the above   example of drug abuse, an experienced clinician might be used to   classify individuals after an interview, or archival records such as   arrest records, employment history, or self-reported drug involvement   might be used to evaluate the efficacy of the proposed scale.</p>
<dl>
  <dt><strong><a name="Split-Half" id="Split-Half"></a>Split Half</strong></dt>
</dl>
—split-half   reliability is assessed by splitting a scale in half and comparing the   summary score for each half to assess consistency in the two estimates.
<dl>
  <dt><strong><a name="Split-Plot" id="Split-Plot"></a>Split-Plot</strong></dt>
</dl>
—a   split-plot design is an experimental design in which levels of one   factor are randomly assigned to blocks and levels of a second factor are   randomly assigned within each block.
<dl>
  <dt><strong><a name="Spurious Results" id="Spurious Results"></a>Spurious Results</strong></dt>
</dl>
—spurious   results are results in which there is an apparent association or   correlation between two variables which are not actually causally   related.  Spurious relationships occur when the correlation between two   variables is not due to any direct causal relationship but is due to   some third variable causing both of the observed variables.  For a   classic example  of a spurious relationship: the relatively high   correlation found between the number of rapes and ice cream sales.  Both   of these variables, it turns out,  tend to be more frequent in warm   weather.
<dl>
  <dt><strong><a name="Stability" id="Stability"></a>Stability</strong></dt>
</dl>
—the   extent to which a process produces the same results at different points   in time.  A common procedure for estimating stability is to compute   reliability such as inter-rater reliability.  This assesses the extent   to which the same rater performing the same task at two different points   in time  produces the same result.  Generally, measures and procedures   in studies should  be stable.
<dl>
  <dt><strong><a name="Standard Deviation" id="Standard Deviation"></a>Standard Deviation</strong></dt>
</dl>
—a   measure of dispersion suitable for interval-level data, computed by   taking the square root of the variance, where variance is the average of   the squared deviations from the mean.  Standard deviation measures the   variability in a population for a variable.
<dl>
  <dt><strong><a name="Standard Error" id="Standard Error"></a>Standard Error</strong></dt>
</dl>
—the   standard deviation for a sampling distribution of a statistic.  The   standard error is usually higher where the standard deviation is high,   but can be reduced by increasing the sample size.  Standard error is   thus often a consideration in power analyses and efforts to compute the   appropriate sample size for a study.
<dl>
  <dt><strong><a name="Standardized Coefficient" id="Standardized Coefficient"></a>Standardized Coefficient</strong></dt>
</dl>
—a   standardized coefficient is a coefficient which has been transformed to   express the coefficient as a multiple of the standard deviation for   that coefficient.  For example, the standardized regression coefficient   expresses the amount of change in the dependent variable in standard   deviations on that variable relative to a change of one standard   deviation in the independent variable.  Standardized coefficients have a   known range (e.g., the standardized regression coefficient ranges from   -1.0 to +1.0) and express a statistic independent of the units actually   used to measure variables in a study.  Thus, for example, the   standardized regression coefficient for income regressed on age for one   study could be compared meaningfully to the standardized regression   coefficient for the same variables in another study even if the   researchers use different units to measure the variables (such as rubles   in one study and dollars in the other).
<dl>
  <dt><strong><a name="Statistical Controls" id="Statistical Controls"></a>Statistical Controls</strong></dt>
</dl>
—when   variables which may confound findings cannot be controlled through   design strategies, they may sometimes be controlled using statistical   procedures.  For example, analysis of covariance permits means for   groups to be compared controlling for covariates, such as age or income.    Thus, although the groups to be compared may differ in age or income   distributions and although those variables were not controlled in the   original design of the experiment, this statistical procedure adjusts   for the influence of these  potentially confounding variables.
<dl>
  <dt><strong><a name="Statistical-Significance" id="Statistical-Significance"></a>Statistical Significance</strong></dt>
</dl>
—statistical   significance is a characterization of some empirical result made by   researchers through tests of statistical significance.  To conclude that   a finding has statistical significance implies that the results are   unlikely to have occurred by chance.  Statistical significance may be   distinguished from clinical significance (such a claim that the results   are of interest to practitioners in a field).
<dl>
  <dt><strong><a name="Stratification" id="Stratification"></a>Stratification</strong></dt>
</dl>
—the   division of a population into mutually exclusive and exhaustive   categories all of which may be included in the final sample.  For   example, a population may be stratified into drug users and non-drug   users and a sample of each group taken for purposes of the study.
<dl>
  <dt><strong><a name="Stratified-Random-Sampling" id="Stratified-Random-Sampling"></a>Stratified Random Sampling</strong></dt>
</dl>
—stratified   random samples are samples in which the population is first divided   into mutually exclusive and exhaustive strata and then individuals are   selected from within each stratum using a probability sampling   procedure.  Every individual within each stratum has equal probability   of being chosen.  However, the probabilities of selection may differ   between strata.  For example, smaller strata are often oversampled in   order to estimate their population parameters with the same precision as   cases in larger strata.
<p>—recently conducted national surveys contain stratified random   samples; if a random sample were obtained, the number of subjects of   some ethnic subgroups would be too small to provide enough information   for analysis.  Consequently, instead of a sample that contains 13%   Blacks, this subgroup could be oversampled to yield a study group that   may contain 26% Blacks.  Whites may have contributed 70% to a random   sample but in this example may only contribute 57% to a stratified   random sample; however, this percentage of Whites should produce   sufficient numbers of subjects on which the data can be analyzed for   that subgroup.</p>
<dl>
  <dt><strong><a name="Structural Equations" id="Structural Equations"></a>Structural Equations</strong></dt>
</dl>
—a   system of mathematical equations used to describe and model the causal   relationships among variables.  Structural equation modeling is another   name often used for path analysis.
<dl>
  <dt><strong><a name="Subject" id="Subject"></a>Subject</strong></dt>
</dl>
—subjects   are individuals who contribute data in a research study.  Often the   term&quot;subjects&quot; is reserved for experimental designs in which some of    the subjects are exposed to a treatment and others are not.
<dl>
  <dt><strong><a name="Surveys" id="Surveys"></a>Surveys</strong></dt>
</dl>
—a   technique for collecting data that asks questions of a sample of   respondents using a self-administered questionnaire or an interviewer in   either a face-to-face setting or over the phone.  Surveys usually take   place at a single point in time.
<p>—an example of a well known survey that utilized the mail is the United States Census. </p>
<dl>
  <dt><strong><a name="Survival Analysis" id="Survival Analysis"></a>Survival Analysis</strong></dt>
</dl>
—a   type of statistical analysis suitable for analyzing the length of time   subjects&quot;survive&quot; or persist in one state rather than changing to some   other state after some treatment event.
<dl>
  <dt><strong><a name="Systematic" id="Systematic"></a>Systematic</strong></dt>
</dl>
—systematic   error is error which displays consistent effects in one direction or   another.  Systematic error, or bias, unlike random error, cannot be   addressed using statistical tests of significance and must be controlled   and eliminated through methodological design strategies.
<dl>
  <dt><strong><a name="Systematic Sampling" id="Systematic Sampling"></a>Systematic Sampling</strong></dt>
</dl>
—instead   of a random number table to select subjects, a list of potential   subjects is obtained, and the names are counted.  The number of   potential subjects is divided by the number of subjects needed for the   data analysis which yields n.  The investigator then selects every nth   person on the list.  For example, if a list has 2100 names, and a power   analysis indicates that the investigators needs 100 subjects to   participate in the study, every twenty-first subject is approach to   participate in the study.
<p>Usually instead of counting from the first subject, a random number   between 1 and 100 (or some other arbitrary number that is reasonably   high) will be generated, and the counting begins from the random number.    If, for whatever reason, the number of subjects needed for the study   is not obtained (e.g., the subject refused to participate) in the first   pass through the list, the process can begin again, using a   different&quot;seed&quot; number—the number at which the first subject is picked. </p>
<dl>
  <dt><strong><a name="t-Test" id="t-Test"></a>t-Test</strong></dt>
</dl>
—a test of   statistical significance used to compare two means for relatively small   sample sizes (n &lt; 30) when the population standard deviation is not   known.  This test relies on Student's t distribution rather than the   normal distribution.  (&quot;Student&quot; was a pen name of the originator of   this test statistic whose company believed publishing in academic   journals was degrading.)
<dl>
  <dt><strong><a name="Target-Population" id="Target-Population"></a>Target Population</strong></dt>
</dl>
—the   group of individuals who is of interest to the researcher.  The sample   population should have essentially the same characteristics as the   target population to ensure that the result of the study are   generalizable.
<p>—examples of target populations are intravenous drug users in large   metropolitan areas, male adolescent high school students in a certain   urban area in the Northeast, or the elderly population in a region of   the United States.</p>
<dl>
  <dt><strong><a name="Telephone-Interview" id="Telephone-Interview"></a>Telephone Interview</strong></dt>
</dl>
—an   interview in which cases are phoned by researchers and questionnaires   administered over the phone.  Telephone interviews are receiving   considerable use today and may be much more cost-effective than   face-to-face interviews conducted through door-to-door visits.  However,   telephone interviews are useless for populations without access to   phones.
<dl>
  <dt><strong><a name="Temporal-Relationship" id="Temporal-Relationship"></a>Temporal Relationship</strong></dt>
</dl>
—a relationship which takes place over time.  For example, causes should always precede effects in time.
<dl>
  <dt><strong><a name="Test Statistic" id="Test Statistic"></a>Test Statistic</strong></dt>
</dl>
—an   index of the size of the observed relationship. e.g., t for the   Student's t-test, r for a Pearson correlation coefficient, etc.
<dl>
  <dt><strong><a name="Test-Retest" id="Test-Retest"></a>Test-Retest</strong></dt>
</dl>
—a   type of reliability demonstrated when the scores of the instrument   correlate highly with a later, readministration of the same measure.    This type of reliability is dependent on the assumption that nothing has   occurred between the two assessments that would affect the test scores.
<p>—for example, a measure that identifies individuals as having drug or   alcohol problems should yield similar results at each assessment.  An   instrument that would classify individuals has drug dependent half of   the time would be of little diagnostic use and would not have much   application in treatment programs. </p>
<dl>
  <dt><strong><a name="Testing Randomization Procedures" id="Testing Randomization Procedures"></a>Testing Randomization Procedures</strong></dt>
</dl>
—randomization   procedures—including both random assignment of cases to experimental   groups and random selection of cases from some population—are most   effective for large numbers.  When small numbers of subjects are   selected or assigned at random, the sample may not be representative of   the population.  For this reason, it is important to test the impact of   randomization procedures.  Does the random sample, for example, include   10% minorities in a population containing 10% minorities?
<dl>
  <dt><strong><a name="Third-Variable-Effects" id="Third-Variable-Effects"></a>Third Variable Effects</strong></dt>
</dl>
—any   time a relationship between two variables is assessed, there is the   question of whether one or more third variables might account for the   observed relationship or affect its magnitude and direction.  For   example, a significant correlation between two variables may be due to a   causal effect of one variable on the other.  But it might also be due   to a third variable causing both of the observed variables.  Another   example of a third variable effect occurs when the magnitude of a   correlation between two variables varies depending on the value of a   third variable.
<dl>
  <dt><strong><a name="Throwing Subjects Out" id="Throwing Subjects Out"></a>Throwing Subjects Out</strong></dt>
</dl>
—discarding   subjects from a study is a very serious decision which, though   sometimes necessary and justified, must always be carefully justified,   limited to as few cases as possible, and documented to assess its   impact.  For example, in a survey, a small number of cases may display   very unusual and even illogical patterns of responses which may be   caused by either extreme respondent bias or data collection error.  If   the patterns displayed provide clear evidence that the data are biased   or inaccurate for a case, then researchers may exclude those cases from   further analysis.
<dl>
  <dt><strong><a name="Tolerance" id="Tolerance"></a>Tolerance</strong></dt>
</dl>
—a   statistical index of colinearity. Computed by (1-R)2  where R is the   multiple R of the individual variable with all the other variables in   the equation.  Thus, low values of tolerance indicate more colinearity.
<dl>
  <dt><strong><a name="Transformations" id="Transformations"></a>Transformations</strong></dt>
</dl>
—transformations   of variables are sometimes used to produce distributions which more   closely meet the assumptions of statistical tests to be used.  For   example, variables which are skew are sometimes transformed to have a   more nearly normal distribution for purposes of statistical tests.
<dl>
  <dt><strong><a name="Treatment Group" id="Treatment Group"></a>Treatment Group</strong></dt>
</dl>
—in   an experimental design the treatment group is a group of subjects   exposed to some treatment or experimental manipulation.  Values of the   dependent variable for that group are then compared to those of a   control group to assess the effect of the treatment.
<dl>
  <dt><strong><a name="Two-Stage-Sampling" id="Two-Stage-Sampling"></a>Two Stage Sampling</strong></dt>
</dl>
—two   stage sampling is a sampling process having two steps or two stages.    For example, the first stage of a city-wide survey might select census   tracts and a second stage might select households.
<dl>
  <dt><strong><a name="Two-Tailed" id="Two-Tailed"></a>Two-Tailed</strong></dt>
</dl>
—a two-tailed test of significance is used when a hypothesis to be tested specifies no direction of effects.
<p>For example, the hypothesis that there is some difference—one way or   the other—between an experimental group and  a control group can be   tested by a two-tailed test.  Significant differences  in either   direction would then be regarded as supporting the hypothesis. </p>
<dl>
  <dt><strong><a name="Type-I-Error" id="Type-I-Error"></a>Type I Error</strong></dt>
</dl>
—Type   I and II errors are terms conventionally applied to particular errors   which may occur in statistical tests of hypotheses.  A Type I error   occurs when the researcher incorrectly concludes that a difference   exists between two means or there is some relationship between two   variables: in other words, there actually is no difference in means or   there is no  relationship between the variables.  A Type I error is   traditionally regarded  as much less desirable than a Type II error, and   a convention commonly used is to set the alpha level (the probability   of a type I error occurring by  chance) to .05.
<dl>
  <dt><strong><a name="Type-II-Error" id="Type-II-Error"></a>Type II Error</strong></dt>
</dl>
—Type   I and II errors are terms conventionally applied to particular errors   which may occur in statistical tests of hypotheses.  A type II error   occurs when the researcher incorrectly concludes that a difference does   not exist between two means or there is no relationship between two   variables, when there actually is a difference in means or there is a   relationship between the variables.  A Type I error is traditionally   regarded as much less desirable than a Type II error, and a convention   commonly used is to set the alpha level (the probability of a type I   error occurring by chance) to .05; while a less well established   convention is to set the beta level (the probability of a type II error   occurring by chance) to .20.
<dl>
  <dt><strong><a name="Underreport" id="Underreport"></a>Underreport</strong></dt>
</dl>
—an   event or condition is underreported when people bias their responses    in the direction of reporting it less often than it actually occurs.     For example, illegal acts such as the use of illicit drugs may be   underreported by respondents out of a concern for the potential legal    consequences of such reports.
<dl>
  <dt><strong><a name="Unobtrusive" id="Unobtrusive"></a>Unobtrusive</strong></dt>
</dl>
—unobtrusive   measures are measures which are less apparent to people being observed.    Examples include measuring the amount of trash in an area or wear on   the floor to estimate the extent to which that area is used.
<dl>
  <dt><strong><a name="Unstandardized Coefficient" id="Unstandardized Coefficient"></a>Unstandardized Coefficient</strong></dt>
</dl>
—unstandardized   coefficients may be contrasted with standardized coefficients.  For   example, an unstandardized regression coefficient has upper and lower   limits which vary depending on the units used to measure the involved   variables.  In contrast, the standardized regression coefficient is   constrained to make +1.00 its maximum possible value and  -1.00 its   lowest possible value regardless of the specific units used.
<dl>
  <dt><strong><a name="Unusual-Characteristics" id="Unusual-Characteristics"></a>Unusual-Characteristics</strong></dt>
</dl>
—unusual   or rare characteristics in a population may require special efforts for   study.  These can include: 1) retrospective case control studies   comparing cases having some rare condition with other cases not having   that  condition; or 2) some form of stratified sampling in which rare   populations are disproportionately oversampled in order to have   sufficient numbers of them to draw statistical inferences.
<dl>
  <dt><strong><a name="Validity" id="Validity"></a>Validity</strong></dt>
</dl>
—the   ability of the scale to measure the concept of interest. Evidence for   the validity of the instrument should be well established and almost   always should be reported in a grant proposal. </div>
    </div>
  <!-- End of Right Column // Page Content --><br class="clearfloat" />
  </div>
<!-- End of Main Content -->
    
<!-- Last Updated -->
  <div class="update">Last Updated: October 3, 2012</div>
<!-- End of Last Updated -->
    
<!-- Footer -->
  <div id="foot-row1">
	<ul class="flist2">
    <li><a href="/index.html">Site Home</a></li>
    <li>|</li>
    <li><a href="http://www.cancer.gov/global/contact">Contact Us</a></li>
    <li>|</li>
    <li><a href="http://www.cancer.gov/policies/disclaimer">Disclaimer Policy</a></li>
    <li>|</li>
    <li><a href="http://www.cancer.gov/global/web/policies/accessibility">Accessibility</a></li>
    <li>|</li>
    <li><a href="http://www.cancer.gov/global/viewing-files">Viewing Files</a></li>
    <li>|</li>
    <li><a href="http://www.cancer.gov/global/web/policies/foia">FOIA</a></li>
    <li>|</li>
	<li><a href="/help.html">Help</a></li>
    <li>|</li>
    <li><a href="/site-map.html">Site Map</a></li>
  </ul>
	<br />

	<ul class="flist2">
    <li><a href="http://www.hhs.gov/">U.S. Department of Health and Human Services</a></li>
    <li>|</li>
  <li><a href="http://www.nih.gov/">National Institutes of Health</a></li>
  <li>|</li>
  <li><a href="http://www.cancer.gov/">National Cancer Institute</a></li>
  <li>|</li>
  <li><a href="http://www.usa.gov/">USA.gov</a></li>
  </ul>
  <div class="nih-tagline">NIH…Turning Discovery Into Health<sup>&#174;</sup></div>
	</div>
  </div>
<!-- End of Footer -->
</div>

<!-- Image map for head-row1 -->
<map name="Map" id="Map">
	<area shape="rect" coords="12,3,294,38" href="http://www.cancer.gov/" alt="National Cancer Institute" />
	<area shape="rect" coords="715,10,892,33" href="http://www.nih.gov" alt="U.S. National Institutes of Health" />
	<area shape="rect" coords="893,10,988,33" href="http://www.cancer.gov/" alt="National Cancer Institute" />
</map>
<!-- End of Image map for head-row1 -->

<!-- GA Code -->
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-25589575-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
<!-- End of GA Code -->
<script language="JavaScript" type="text/javascript" src="/JS/Omniture/WA_DCCPS_PageLoad.js"></script>
</body>
</html>